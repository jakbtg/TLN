{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Mapping of frames in WordNet synsets**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frames estratti con la funzione getFrameSetForStudent() per il cognome Grandi:\n",
    "| ID | Frame |\n",
    "| --- | --- |\n",
    "| 2658 | Suicide_attack |\n",
    "| 1633 | Board_vehicle |\n",
    "| 1260 | Simple_name |\n",
    "| 1871 | Access_scenario |\n",
    "| 652 | Eclipse |\n",
    "\n",
    "Dato che: \n",
    " - Suicide_attack\n",
    " - Board_vehicle \n",
    " - Simple_name \n",
    " - Access_scenario \n",
    "\n",
    "non sono presenti in WordNet, sono stati scelti rispettivamente:\n",
    "- Suicide\n",
    "- Vehicle\n",
    "- Name\n",
    "- Access\n",
    "\n",
    "In pratica dovr√≤: associare dei synset al frame name, frame elements e LUs presi dai 5 del frameset.\n",
    "Considerando come contesto di disambiguazione la frame name definition, frame element definition e LU definition, rispettivamente.\n",
    "Come contesto dei sensi considero le varie definizioni del termine principale del frame name, la gloss, esempi e iponimi e iperonimi. E lo stesso per FE e LU\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import framenet as fn\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni di utility per il preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords and punctuation from a given sentence\n",
    "def remove_stopwords(sentence):\n",
    "    stop_words = []\n",
    "    with open('/Users/jak/Documents/Uni/TLN/TLN/Radicioni/data/stop_words_FULL.txt', 'r') as f:\n",
    "        for line in f:\n",
    "            stop_words.append(line.strip())\n",
    "    sentence = [w for w in sentence if w not in stop_words]\n",
    "    return sentence\n",
    "\n",
    "# Tokenize a given list of words\n",
    "def tokenize(list):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    for i in range(len(list)):\n",
    "        list[i] = tokenizer.tokenize(list[i])\n",
    "    return list\n",
    "\n",
    "# ---- POSSIBLY NOT NEEDED ----\n",
    "# Get content words from a given sentence\n",
    "def get_content_words(sentence):\n",
    "    sentence = ''.join(sentence)\n",
    "    sentence = set(sentence.lower().split())\n",
    "    sentence = remove_stopwords(sentence)\n",
    "    return sentence\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estrazione del contesto dei sensi\n",
    "\n",
    "Creo una lista di content words per un dato synset, cercando all'interno di:\n",
    "- definizione del synset\n",
    "- esempi del synset\n",
    "- definizioni di iponimi e iperonimi\n",
    "- esempi di iponimi e iperonimi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['job', 'box-shaped', 'guzzler', 'traveling', 'automobile', 'equipped', 'engine', 'lap', 'seating', 'fallen', 'rails', 'low', 'people', 'powered', 'owned;', 'fast', 'luggage', 'fuel', '1908', 'parade', 'sports', 'small', 'subcompact', 'terrain', 'repair', 'steam-powered', 'rear', 'gasoline', 'cruise', 'bus', 'policemen', 'ford', 'loaner', 'pulls', 'used-car', 'seat', 'combustion', 'gas', 'efficiency', 'term', 'henry', 'minivan', 'sales', 'engine;', 'ambulance', 'stock', 'long', 'driven', 'replacement', 'lent', 'acceleration', 'compact', 'wheels;', 'radiotelephonic', 'races', 'wheeled', 'course', 'called', 'limousine', 'pace', 'high-performance', 'front', 'stanley', 'steamer', 'electricity', 'jeep', 'early', 'resembles', 'beach', 'top', 'seats;', 'built', 'high-powered', 'passengers', 'carriages', 'streets;', 'coupe', 'fixed', 'leads', 'chassis', 'regular', 'self-propelled', 'internal', 'cruiser', 'propelled', 'communications', 'hot', 'wagon', 'sedan', 'door', 'hardtop', 'competes', \"dealers'\", 'horse-drawn', 'carriage', 'touring', 'rod', 'exchange', 'takes', 'horseless', 'rigid', 'luxurious', 'car;', 'model', 'passenger', 'closed', 'speed', 'motor', 'persons', 'space', 'minicar', 'automobiles', 'removed', 'removable', 'utility', '1927', 'truck', 'economical', 'fenders', 'cab', 'hatchback', 'rough', 'sport', 'family', 'money', 'cars', 'compartment', 'unreliable', 'four-wheel', 'body', 'person', 'convertible', 'open', 'replaced', 'chauffeur', 'large', 'seats', 'modified', 'roadster', 'folded', 'hospitals', 'car', 'rumble', 'suitable', 'work', 'vehicle', 'mass-produced', 'van;', 'electric', 'drive', 'doors', 'folding', 'headquarters', 'competing', 'racer', 'increase', 'smaller']\n",
      "157\n",
      "van;\n"
     ]
    }
   ],
   "source": [
    "# Get context for a given synset\n",
    "def get_context(synset):\n",
    "    context = set(synset.name().split('.')[0].split('_'))\n",
    "    context.update(synset.definition().lower().split())\n",
    "    for example in synset.examples():\n",
    "        context.update(example.lower().split())\n",
    "    for hypo in synset.hyponyms():\n",
    "        context.update(hypo.name().split('.')[0].split('_'))\n",
    "        context.update(hypo.definition().lower().split())\n",
    "        for example in hypo.examples():\n",
    "            context.update(example.lower().split())\n",
    "    for hyper in synset.hypernyms():\n",
    "        context.update(hyper.name().split('.')[0].split('_'))\n",
    "        context.update(hyper.definition().lower().split())\n",
    "        for example in hyper.examples():\n",
    "            context.update(example.lower().split())\n",
    "    context = remove_stopwords(context)\n",
    "    # context = tokenize(context) Maybe not needed\n",
    "    for word in context:\n",
    "        word = word.rstrip()\n",
    "    return context\n",
    "\n",
    "context = get_context(wn.synset('car.n.01'))\n",
    "print(context)\n",
    "print(len(context))\n",
    "print(context[-10].strip())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estraggo il contesto dei sensi per ogni synset di una parola data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['job', 'box-shaped', 'guzzler', 'traveling', 'automobile', 'equipped', 'engine', 'lap', 'seating', 'fallen', 'rails', 'low', 'people', 'powered', 'owned;', 'fast', 'luggage', 'fuel', '1908', 'parade', 'sports', 'small', 'subcompact', 'terrain', 'repair', 'steam-powered', 'rear', 'gasoline', 'cruise', 'bus', 'policemen', 'ford', 'loaner', 'pulls', 'used-car', 'seat', 'combustion', 'gas', 'efficiency', 'term', 'henry', 'minivan', 'sales', 'engine;', 'ambulance', 'stock', 'long', 'driven', 'replacement', 'lent', 'acceleration', 'compact', 'wheels;', 'radiotelephonic', 'races', 'wheeled', 'course', 'called', 'limousine', 'pace', 'high-performance', 'front', 'stanley', 'steamer', 'electricity', 'jeep', 'early', 'resembles', 'beach', 'top', 'seats;', 'built', 'high-powered', 'passengers', 'carriages', 'streets;', 'coupe', 'fixed', 'leads', 'chassis', 'regular', 'self-propelled', 'internal', 'cruiser', 'propelled', 'communications', 'hot', 'wagon', 'sedan', 'door', 'hardtop', 'competes', \"dealers'\", 'horse-drawn', 'carriage', 'touring', 'rod', 'exchange', 'takes', 'horseless', 'rigid', 'luxurious', 'car;', 'model', 'passenger', 'closed', 'speed', 'motor', 'persons', 'space', 'minicar', 'automobiles', 'removed', 'removable', 'utility', '1927', 'truck', 'economical', 'fenders', 'cab', 'hatchback', 'rough', 'sport', 'family', 'money', 'cars', 'compartment', 'unreliable', 'four-wheel', 'body', 'person', 'convertible', 'open', 'replaced', 'chauffeur', 'large', 'seats', 'modified', 'roadster', 'folded', 'hospitals', 'car', 'rumble', 'suitable', 'work', 'vehicle', 'mass-produced', 'van;', 'electric', 'drive', 'doors', 'folding', 'headquarters', 'competing', 'racer', 'increase', 'smaller'], ['freight', 'sumer', 'rails', 'stopping', 'container', 'van', 'sorted', 'bc', 'three', 'people', 'bags', 'fuel', 'slip', 'handcar', 'small', 'cabin', 'moves', \"guard's\", 'transported', 'vehicles', 'carried', 'transporting', 'wheeled', 'wheels', 'chairs', 'crew;', 'tender', 'railcar', 'club', 'mail', 'tables', 'water', 'jumped', 'passengers', 'oldest', 'things', \"passengers'\", 'occupied', 'propelled', '(great', 'passenger', 'closed', 'motor', 'britain)', 'baggage', 'lounge', 'train', 'railway', 'hand', 'cars', 'train;', 'attached', '3500', 'detached', 'carries', 'railroad', 'syria', 'guard', 'locomotive', 'car', 'vehicle', 'ride', 'coach', 'bar', 'adapted', 'carry'], ['larger', 'cargo', 'airship', 'power', 'compartment', 'suspended', 'chamber,', 'plant', 'personnel', 'separate', 'carries', 'section,', 'car', 'area', 'room', 'enclosed', 'partitioned'], ['larger', 'compartment', 'chamber,', 'separate', 'floor', 'section,', 'car', 'area', 'ride', 'top', 'room', 'enclosed', 'passengers', 'partitioned'], ['larger', 'railway', 'conveyance', 'freight', 'cable', 'compartment', 'chamber,', 'separate', 'partitioned', 'section,', 'car', 'area', 'top', 'room', 'enclosed', 'mountain', 'passengers']]\n"
     ]
    }
   ],
   "source": [
    "# TODO: da cambiare di sihuro deh\n",
    "# Get context for all synsets of a given word\n",
    "def get_context_all(word):\n",
    "    context = []\n",
    "    for synset in wn.synsets(word):\n",
    "        context.append(get_context(synset))\n",
    "    return context\n",
    "\n",
    "context = get_context_all('car')\n",
    "print(context)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['befogged.a', 'conceal.v', 'subregion', 'observer,', 'shroud', 'occlude.v', 'element', 'body;', \".'\", 'bungalow', 'close', 'indicate', 'degree', 'screen.v', 'total', 'momentarily', 'covered', 'mists', 'block;', 'wholly', 'opening', 'covered.a', 'veil.v', 'small', 'clouds', 'illumination', 'direct', 'visible', 'disguise,', 'screens', 'mask', 'shroud.v', 'alters', 'event', \"foliage.'\", 'flashed', 'green', 'shrouded', 'entity', 'obstruction', 'obscure', 'aesthetics', 'observers.', 'obscure.v', 'gate', 'eclipse.', 'house', 'hide', 'concealed', 'position', 'eclipse.v', 'occlusion.n', \"tower.'\", 'panel', 'obstruct', \"'the\", 'blocks', \"side.'\", 'shrouded.a', 'occultation.n', 'masked', 'obscured,', 'phrases', 'cloaked.a', 'veiled.a', 'cover', 'wearing', 'fence', 'view.', 'view', 'frame', 'big', 'masked.a', 'up,', 'source', 'conceal,', 'obscuring', 'top', 'allow', 'beclouded.a', 'partially', 'object', 'obstruction.', \"road.'\", 'blot', 'clouds.', \"treetops.'\", 'garden', 'shelter', 'veil', \"europe.'\", 'screen', 'stop,', 'relative', 'celestian', 'seen;', 'reported', 'obscured', 'hedge', 'enshroud.v', 'screened', 'assumed', 'gazebo', 'telescope', 'cloak.v', 'fog', 'conceal', 'blocked', \"'a\", 'bulb', 'vantage_point', 'sight\"', 'astronomical', 'concealed.a', \"passersby.'.\", 'cod:', '\"from', 'reference', 'map', 'observer', 'enshrouded.a', \"'wispy\", 'screened.a', 'cover.v', 'cloak', 'eclipsed', 'out.v', 'includes', 'protect,', 'celestial', 'passage', 'eclipse.n', 'hide.v', 'befog.v', 'body', 'vantage_point.', 'obscured.a', 'eclipse', 'present,', 'extent', 'completely', 'view\"', 'obstructing', 'mask.v', 'fn:', 'positions', 'obstruct.v', 'hidden.a', 'becloud.v', 'whereby,', 'light', 'block.v', 'block', 'surrounds', 'thick']\n",
      "155\n",
      "befogged.a\n",
      "fog\n"
     ]
    }
   ],
   "source": [
    "# Get frame context for a given frame\n",
    "def get_frame_context(frame):\n",
    "    context = set(frame.definition.lower().split())\n",
    "    context.update(frame.name.lower().split())\n",
    "    # FEs = frame.FE.keys()\n",
    "    # for fe in FEs:\n",
    "    #     fed = frame.FE[fe]\n",
    "    #     context.update(fed.definition.lower().split())\n",
    "    #     context.update(fe.lower().split())\n",
    "    for fe in frame.FE:\n",
    "        context.update(frame.FE[fe].definition.lower().split())\n",
    "        context.update(fe.lower().split())\n",
    "    for lu in frame.lexUnit:\n",
    "        context.update(lu.lower().split())\n",
    "        # context.update(lu.lower().split('.')[0])\n",
    "        context.update(frame.lexUnit[lu].definition.lower().split())\n",
    "    # LUs = frame.lexUnit.keys()\n",
    "    # lus = frame.lexUnit\n",
    "    # for lu in LUs:\n",
    "    #     context.update(lu.lower().split('.')[0])\n",
    "    #     context.update(lus[lu].definition.lower().split())\n",
    "    # for lu in frame.lexUnit:\n",
    "    #     context.update(lu.name.lower().split())\n",
    "    #     context.update(lu.definition.lower().split())\n",
    "    #     for example in lu.example:\n",
    "    #         context.update(example.lower().split())\n",
    "    context = remove_stopwords(context)\n",
    "    return context\n",
    "\n",
    "context = get_frame_context(fn.frame('Eclipse'))\n",
    "print(context)\n",
    "print(len(context))\n",
    "for elem in context:\n",
    "    if elem in 'befogged.a':\n",
    "        print(elem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the frameset in a dictionary\n",
    "# frames = {\n",
    "#     '2658': 'Suicide_attack',\n",
    "#     '1633': 'Board_vehicle',\n",
    "#     '1260': 'Simple_name',\n",
    "#     '1871': 'Access_scenario',\n",
    "#     '652': 'Eclipse'\n",
    "# }\n",
    "\n",
    "# for key in frames:\n",
    "#     print(fn.frame(frames[key]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5587bf738ccec4bb524b17f914a1c07eb93a384af8fabdf9504251bc61fb6171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
