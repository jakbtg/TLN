{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Automatic Summarization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import random\n",
    "import math"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvo i path dei documenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_paths = ['../data/docs/Andy-Warhol.txt',\n",
    "'../data/docs/Ebola-virus-disease.txt',\n",
    "'../data/docs/Life-indoors.txt',\n",
    "'../data/docs/Napoleon-wiki.txt', \n",
    "'../data/docs/Trump-wall.txt']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Avrei potuto usare le stopwords di *nltk* ed anche il tokenizer *RegexpTokenizer* per rimuovere la punteggiatura durante il processo di tokenizzazione, ma ho scoperto dell'esistenza di questi ultimi solamente dopo aver implementato le seguenti funzioni. Per cui ho lasciato queste funzioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful to remove punctuation from first or last char of a token \n",
    "# - Esempio: senza questa funzione \"It's\" diventa \"It\" e \"'s\"\n",
    "# - It viene eliminato perchè è una stopword, mentre 's non viene eliminato perchè non rientra nè tra le stopwords nè tra la punteggiatura\n",
    "# - Con questa funzione rimuovo ' da 's e poi rimuovo nuovamente eventuali stopwords\n",
    "def remove_first_last(tokens, punct, stop):\n",
    "    for i in range(len(tokens)):\n",
    "        for p in punct:\n",
    "            if tokens[i].startswith(p):\n",
    "                tokens[i] = tokens[i][1:]\n",
    "            if tokens[i].endswith(p):\n",
    "                tokens[i] = tokens[i][:-1]\n",
    "    tokens = [t for t in tokens if t not in stop]\n",
    "    return tokens\n",
    "\n",
    "# Remove stopwords and punctuation from the text, tokenize it and lemmatize it\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    stop = []\n",
    "    with open('../data/stop_words_FULL.txt', 'r') as f:\n",
    "        stop = f.read().splitlines()\n",
    "    stop = set(stop)\n",
    "    punct = ['.', ',', '!', '?', ':', ';', '(', ')', '[', ']', '{', '}', '\"', \"'\", '``', \"''\", '...', '’', '“', '”', '‘', '-', '$', '–']\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in stop and t not in punct]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = list(set([lemmatizer.lemmatize(t) for t in tokens]))\n",
    "    tokens = remove_first_last(tokens, punct, stop)\n",
    "    return tokens"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing del file di input Nasari e creazione dizionario di vettori Nasari\n",
    "\n",
    "(salvo anche lo score anche se in realtà non verrà usato)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parsing the Nasari file and creating a dictionary with:\n",
    "# - key: word\n",
    "# - value: dictionary with:\n",
    "#          - key: lemma\n",
    "#          - value: score\n",
    "nasari = {}\n",
    "with open('../data/dd-small-nasari-15.txt', 'r') as f:\n",
    "    lines = [line.rstrip('\\n') for line in f]\n",
    "    for line in lines:\n",
    "        line = line.split(';')\n",
    "        tmp = {}\n",
    "        for lemma in line[2:]:\n",
    "            lemma = lemma.split('_')\n",
    "            if len(lemma) > 1:\n",
    "                tmp[lemma[0]] = lemma[1]\n",
    "        nasari[line[1].lower()] = tmp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvo i documenti di input\n",
    "\n",
    "Rendo ogni documento una lista di paragrafi, ogni paragrafo è una linea del documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save document\n",
    "def save_doc(filename):\n",
    "    doc = []\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [line.rstrip('\\n') for line in f]\n",
    "        for line in lines:\n",
    "            if '#' not in line and line != '': # remove empty lines and the first line with the link\n",
    "                doc.append(line)\n",
    "    return doc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Individuate the topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get title from document, considering the first line\n",
    "def get_title(filename):\n",
    "    doc = save_doc(filename)\n",
    "    return doc[0]\n",
    "\n",
    "# Get topic words from the title checking if they are in the Nasari dictionary\n",
    "def get_topic_words(title):\n",
    "    tokens = preprocess(title)\n",
    "    topic_words = [t for t in tokens if t in nasari.keys()]\n",
    "    return topic_words\n",
    "\n",
    "# Used only for testing\n",
    "# Get random paragraph topic words from the document (not the title)\n",
    "def get_random_paragraph(filename):\n",
    "    doc = save_doc(filename)\n",
    "    paragraph = random.choice(doc[1:])\n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Create the context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the context for a document title \n",
    "# - Return a list of dictionaries associated to the topic words of the title if they are in the Nasari dictionary\n",
    "def create_context(title):\n",
    "    topic_words = get_topic_words(title)\n",
    "    context_vector = [nasari[word] for word in topic_words]\n",
    "    return context_vector\n",
    "\n",
    "# Create the context for a paragraph\n",
    "# - Return a list of dictionaries associated to the topic words of the paragraph if they are in the Nasari dictionary\n",
    "def create_paragraph_context(paragraph):\n",
    "    topic = [w for w in paragraph if w in nasari.keys()]\n",
    "    context_vector = [nasari[word] for word in topic]\n",
    "    return context_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retain paragraphs whose sentences contain the most salient terms, based on the Weighted Overlap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementazione della Weighted Overlap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get overlap between a context topic words and a paragraph topic words \n",
    "def get_overlap(context, paragraph):\n",
    "    overlap = set()\n",
    "    for w in paragraph:\n",
    "        for dict in context:\n",
    "            if w in dict.keys():\n",
    "                overlap.add(w)\n",
    "    return overlap\n",
    "\n",
    "# Get rank as the position of a lemma in the vector\n",
    "def get_rank(lemma, vector):\n",
    "    min = math.inf\n",
    "    for dict in vector:\n",
    "        i = 1\n",
    "        for key in dict.keys():\n",
    "            if key == lemma:\n",
    "                if i < min:\n",
    "                    min = i\n",
    "            i += 1\n",
    "    return min\n",
    "\n",
    "# Compute weighted overlap between two vectors\n",
    "def weighted_overlap(context, paragraph, par_context):\n",
    "    overlap = get_overlap(context, paragraph)\n",
    "    if overlap:\n",
    "        i = 1\n",
    "        num = 0\n",
    "        den = 0\n",
    "        for lemma in overlap:\n",
    "            den += get_rank(lemma, context) + get_rank(lemma, par_context) # This should be the num but since it is to the power of -1 I can put it in the den\n",
    "            num += 2 * i # This should be the den but since it is to the power of -1 I can put it in the num\n",
    "            i += 1\n",
    "        return num / den\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo della Weighted Overlap per ogni paragrafo di un documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the weighted overlap between a document title and all the paragraphs\n",
    "def weight_doc(filename):\n",
    "    title = get_title(filename)\n",
    "    context = create_context(title)\n",
    "    doc = save_doc(filename)\n",
    "    paragraphs = [preprocess(par) for par in doc[1:]]\n",
    "    par_context = [create_paragraph_context(par) for par in paragraphs]\n",
    "    weighted_overlap_list = [weighted_overlap(context, paragraphs[i], par_context[i]) for i in range(len(paragraphs))]\n",
    "    return weighted_overlap_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selezione dei paragrafi migliori\n",
    "\n",
    "Verrà selezionato il 70 - 80 - 90% dei paragrafi con peso maggiore, a seconda della percentuale richiesta.  \n",
    "(Può essere utilizzato select_best_paragraphs per stampare il documento riassunto della percentuale richiesta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many paragraphs to keep, given a percentage\n",
    "def get_threshold(doc, percentage):\n",
    "    total = len(doc[1:])\n",
    "    threshold = math.ceil(total * percentage)\n",
    "    return threshold\n",
    "\n",
    "# Select the best paragraphs given a percentage\n",
    "def select_best_paragraphs(filename, percentage):\n",
    "    weighted_overlap_list = weight_doc(filename)\n",
    "    doc = save_doc(filename)\n",
    "    paragraphs = doc[1:]\n",
    "    best_paragraphs = [doc[0]]\n",
    "    threshold = get_threshold(doc, percentage)\n",
    "    for i in range(int(threshold)):\n",
    "        best_paragraphs.append(paragraphs[weighted_overlap_list.index(max(weighted_overlap_list))])\n",
    "        weighted_overlap_list[weighted_overlap_list.index(max(weighted_overlap_list))] = -1\n",
    "    return best_paragraphs\n",
    "\n",
    "# select_best_paragraphs(doc_paths[0], 0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Costruzione del gold per la valutazione\n",
    "\n",
    "Sarà un dizionario con chiave il nome del documento e valore una lista di paragrafi, dove ogni paragrafo è una lista parole rilevanti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gold_docs will be a dictionary with:\n",
    "# - key: title of the document\n",
    "# - value: list of paragraphs with each element as a list of preprocessed words - which are considered as salient terms\n",
    "gold_docs = {}\n",
    "\n",
    "def doc_preprocess(filename):\n",
    "    doc = save_doc(filename)\n",
    "    paragraphs = [preprocess(par) for par in doc[1:]]\n",
    "    return paragraphs\n",
    "\n",
    "for path in doc_paths:\n",
    "    title = get_title(path)\n",
    "    gold_docs[title] = doc_preprocess(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funzioni per creare il summary e il gold utili per la valutazione\n",
    "\n",
    "- Il summary sarà in realtà un set di termini rilevanti per il documento riassunto\n",
    "- Il gold sarà un set di termini rilevanti per il documento originale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create summary as a set of relevant words for a summarized document\n",
    "def create_summary(filename, percentage):\n",
    "    best_paragraphs = select_best_paragraphs(filename, percentage)\n",
    "    summary = [preprocess(par) for par in best_paragraphs[1:]]\n",
    "    summary = [word for par in summary for word in par] \n",
    "    return set(summary)\n",
    "\n",
    "# Create gold as a set of relevant words for an original document\n",
    "def create_gold(filename):\n",
    "    gold = gold_docs[get_title(filename)]\n",
    "    gold = [word for par in gold for word in par]\n",
    "    return set(gold)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo della BLEU e ROUGE\n",
    "\n",
    "Saranno date dal confronto tra il riassunto di riferimento (gold) e il riassunto generato (summary).\n",
    "\n",
    "- **BLEU**: Misura la precision: ovvero quante parole del riassunto generato sono contenute nel riassunto di riferimento.  \n",
    "BLEU = num(gold & summary) / num(summary)\n",
    "\n",
    "- **ROUGE**: Misura la recall: ovvero quante parole del riassunto di riferimento sono contenute nel riassunto generato.  \n",
    "ROUGE = num(gold & summary) / num(gold)\n",
    "\n",
    "  \n",
    "*Note*:  \n",
    "- BLEU sarà sempre 1 perché il riassunto generato è estrattivo, non astrattivo. Pertanto non verrà generata alcuna parola non presente nel riassunto di riferimento.  \n",
    "- ROUGE invece è più indicativo, dipende da quante parole del riassunto di riferimento sono state estratte.\n",
    "- Ho inserito la percentuale 100% solamente per vedere se il codice funzionasse correttamente restituendo ROUGE = 1, len(summary) = len(gold) e threshold = max numero di paragrafi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "DOC: Andy Warhol: Why the great Pop artist thought ‘Trump is sort of cheap’\n",
      "\tThreshold with percentage 70.0%: 14 out of 19 paragraphs\n",
      "\tSummary length: 303\n",
      "\tGold length: 409\n",
      "\tBLEU score with 70.0%: 1.0\n",
      "\tROUGE score with 70.0%: 0.7408312958435208\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 80.0%: 16 out of 19 paragraphs\n",
      "\tSummary length: 355\n",
      "\tGold length: 409\n",
      "\tBLEU score with 80.0%: 1.0\n",
      "\tROUGE score with 80.0%: 0.8679706601466992\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 90.0%: 18 out of 19 paragraphs\n",
      "\tSummary length: 398\n",
      "\tGold length: 409\n",
      "\tBLEU score with 90.0%: 1.0\n",
      "\tROUGE score with 90.0%: 0.9731051344743277\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 100%: 19 out of 19 paragraphs\n",
      "\tSummary length: 409\n",
      "\tGold length: 409\n",
      "\tBLEU score with 100%: 1.0\n",
      "\tROUGE score with 100%: 1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DOC: Ebola virus disease\n",
      "\tThreshold with percentage 70.0%: 19 out of 27 paragraphs\n",
      "\tSummary length: 548\n",
      "\tGold length: 569\n",
      "\tBLEU score with 70.0%: 1.0\n",
      "\tROUGE score with 70.0%: 0.9630931458699473\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 80.0%: 22 out of 27 paragraphs\n",
      "\tSummary length: 549\n",
      "\tGold length: 569\n",
      "\tBLEU score with 80.0%: 1.0\n",
      "\tROUGE score with 80.0%: 0.9648506151142355\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 90.0%: 25 out of 27 paragraphs\n",
      "\tSummary length: 561\n",
      "\tGold length: 569\n",
      "\tBLEU score with 90.0%: 1.0\n",
      "\tROUGE score with 90.0%: 0.9859402460456942\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 100%: 27 out of 27 paragraphs\n",
      "\tSummary length: 569\n",
      "\tGold length: 569\n",
      "\tBLEU score with 100%: 1.0\n",
      "\tROUGE score with 100%: 1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DOC: How people around the world are coping with life indoors\n",
      "\tThreshold with percentage 70.0%: 9 out of 12 paragraphs\n",
      "\tSummary length: 139\n",
      "\tGold length: 175\n",
      "\tBLEU score with 70.0%: 1.0\n",
      "\tROUGE score with 70.0%: 0.7942857142857143\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 80.0%: 10 out of 12 paragraphs\n",
      "\tSummary length: 145\n",
      "\tGold length: 175\n",
      "\tBLEU score with 80.0%: 1.0\n",
      "\tROUGE score with 80.0%: 0.8285714285714286\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 90.0%: 11 out of 12 paragraphs\n",
      "\tSummary length: 153\n",
      "\tGold length: 175\n",
      "\tBLEU score with 90.0%: 1.0\n",
      "\tROUGE score with 90.0%: 0.8742857142857143\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 100%: 12 out of 12 paragraphs\n",
      "\tSummary length: 175\n",
      "\tGold length: 175\n",
      "\tBLEU score with 100%: 1.0\n",
      "\tROUGE score with 100%: 1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DOC: Napoleone Bonaparte.\n",
      "\tThreshold with percentage 70.0%: 12 out of 17 paragraphs\n",
      "\tSummary length: 226\n",
      "\tGold length: 349\n",
      "\tBLEU score with 70.0%: 1.0\n",
      "\tROUGE score with 70.0%: 0.6475644699140402\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 80.0%: 14 out of 17 paragraphs\n",
      "\tSummary length: 268\n",
      "\tGold length: 349\n",
      "\tBLEU score with 80.0%: 1.0\n",
      "\tROUGE score with 80.0%: 0.7679083094555874\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 90.0%: 16 out of 17 paragraphs\n",
      "\tSummary length: 316\n",
      "\tGold length: 349\n",
      "\tBLEU score with 90.0%: 1.0\n",
      "\tROUGE score with 90.0%: 0.9054441260744985\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 100%: 17 out of 17 paragraphs\n",
      "\tSummary length: 349\n",
      "\tGold length: 349\n",
      "\tBLEU score with 100%: 1.0\n",
      "\tROUGE score with 100%: 1.0\n",
      "----------------------------------------------------------------------------------------------------\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DOC: The Trump wall, commonly referred to as \"The Wall\", was an expansion of the Mexico–United States barrier during the U.S. presidency of Donald Trump. Throughout his 2016 presidential campaign, Trump called for the construction of a border wall. He said that, if elected, he would \"build the wall and make Mexico pay for it\". Then-Mexican president Enrique Peña Nieto said that Mexico would not pay for the wall.\n",
      "\tThreshold with percentage 70.0%: 44 out of 62 paragraphs\n",
      "\tSummary length: 753\n",
      "\tGold length: 881\n",
      "\tBLEU score with 70.0%: 1.0\n",
      "\tROUGE score with 70.0%: 0.8547105561861521\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 80.0%: 50 out of 62 paragraphs\n",
      "\tSummary length: 791\n",
      "\tGold length: 881\n",
      "\tBLEU score with 80.0%: 1.0\n",
      "\tROUGE score with 80.0%: 0.8978433598183881\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 90.0%: 56 out of 62 paragraphs\n",
      "\tSummary length: 840\n",
      "\tGold length: 881\n",
      "\tBLEU score with 90.0%: 1.0\n",
      "\tROUGE score with 90.0%: 0.9534619750283768\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\tThreshold with percentage 100%: 62 out of 62 paragraphs\n",
      "\tSummary length: 881\n",
      "\tGold length: 881\n",
      "\tBLEU score with 100%: 1.0\n",
      "\tROUGE score with 100%: 1.0\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compute BLEU score for a document\n",
    "def bleu(summary, gold):\n",
    "    intersection = summary.intersection(gold)\n",
    "    bleu = len(intersection) / len(summary)\n",
    "    return bleu\n",
    "\n",
    "# Compute ROUGE score for a document\n",
    "def rouge(summary, gold):\n",
    "    intersection = summary.intersection(gold)\n",
    "    rouge = len(intersection) / len(gold)\n",
    "    return rouge\n",
    "\n",
    "# Run the summarization algorithm for all the documents with different percentages\n",
    "for path in doc_paths:\n",
    "    print('-' * 100)\n",
    "    print(f'DOC: {get_title(path)}')\n",
    "    n_par = len(save_doc(path)[1:])\n",
    "    percents = [0.7, 0.8, 0.9, 1]\n",
    "    for p in percents:\n",
    "        threshold = get_threshold(save_doc(path), p)\n",
    "        summary = create_summary(path, p)\n",
    "        gold = create_gold(path)\n",
    "        print(f'\\tThreshold with percentage {p*100}%: {threshold} out of {n_par} paragraphs')\n",
    "        print(f'\\tSummary length: {len(summary)}')\n",
    "        print(f'\\tGold length: {len(gold)}')\n",
    "        print(f'\\tBLEU score with {p*100}%: {bleu(summary, gold)}')\n",
    "        print(f'\\tROUGE score with {p*100}%: {rouge(summary, gold)}')\n",
    "        print('-' * 100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5587bf738ccec4bb524b17f914a1c07eb93a384af8fabdf9504251bc61fb6171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
