{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Concept Similarity with WordNet**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import wordnet as wn\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wu & Palmer Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Depth of a synset - number of steps from the synset to the root\n",
    "def depth(s):\n",
    "    if s is None:\n",
    "        return -1\n",
    "    hypernyms = s.hypernyms()\n",
    "    if len(hypernyms) == 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1 + max([depth(h) for h in hypernyms]) # add 1 to get the last step to the synset s\n",
    "\n",
    "# Get all hypernyms of a synset (including itself)\n",
    "def all_hypernyms(s):\n",
    "    hypernyms = [s]\n",
    "    for h in s.hypernyms():\n",
    "        hypernyms.extend(all_hypernyms(h))\n",
    "    return hypernyms\n",
    "\n",
    "# Lowest Common Subsumer\n",
    "def lcs(s1, s2):\n",
    "    hyper1 = all_hypernyms(s1)\n",
    "    hyper2 = all_hypernyms(s2)\n",
    "    if len(hyper1) == 0 or len(hyper2) == 0:\n",
    "        return None\n",
    "    candidates = set(hyper1).intersection(set(hyper2))\n",
    "    if len(candidates) > 0:\n",
    "        return max(candidates, key=depth)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Wu and Palmer similarity\n",
    "def wup_sim(s1, s2):\n",
    "    lcs_syn = lcs(s1, s2)\n",
    "    if lcs_syn is None:\n",
    "        return 0\n",
    "    return 2 * depth(lcs_syn) / (depth(s1) + depth(s2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shortest Path Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find max depth of all synsets in wordnet\n",
    "def max_depth():\n",
    "    max = 0\n",
    "    for synset in wn.all_synsets():\n",
    "        d = depth(synset)\n",
    "        if d > max:\n",
    "            max = d\n",
    "    return max\n",
    "\n",
    "max_depth = max_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synset('cat.n.01')\n",
      "[Synset('cat.n.01'), Synset('feline.n.01'), Synset('carnivore.n.01'), Synset('placental.n.01'), Synset('mammal.n.01'), Synset('vertebrate.n.01'), Synset('chordate.n.01'), Synset('animal.n.01'), Synset('organism.n.01'), Synset('living_thing.n.01'), Synset('whole.n.02'), Synset('object.n.01'), Synset('physical_entity.n.01'), Synset('entity.n.01')]\n",
      "[Synset('cat.n.01'), Synset('feline.n.01'), Synset('carnivore.n.01'), Synset('placental.n.01'), Synset('mammal.n.01'), Synset('vertebrate.n.01'), Synset('chordate.n.01'), Synset('animal.n.01'), Synset('organism.n.01'), Synset('living_thing.n.01'), Synset('whole.n.02'), Synset('object.n.01'), Synset('physical_entity.n.01'), Synset('entity.n.01')]\n",
      "0\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "# Find shortest path between two synsets\n",
    "def shortest_path(s1, s2):\n",
    "    lcs_syn = lcs(s1, s2)\n",
    "    if lcs_syn is None:\n",
    "        return max_depth\n",
    "    return depth(s1) + depth(s2) - 2 * depth(lcs_syn)\n",
    "\n",
    "# Shortest path similarity\n",
    "def short_path_sim(s1, s2):\n",
    "    return 2 * max_depth - shortest_path(s1, s2)\n",
    "\n",
    "# Prove\n",
    "print(lcs(wn.synset('cat.n.01'), wn.synset('cat.n.01')))\n",
    "print(all_hypernyms(wn.synset('cat.n.01')))\n",
    "print(all_hypernyms(wn.synset('cat.n.01')))\n",
    "print(shortest_path(wn.synset('cat.n.01'), wn.synset('cat.n.01')))\n",
    "print(short_path_sim(wn.synset('cat.n.01'), wn.synset('cat.n.01')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dato che l'input in WordSim353 Ã¨ una coppia di termini, mentre le tre formule utilizzano sensi, per calcolare la similarity fra i 2 termini prendiamo la massima similarity fra tutti i sensi del primo termine e tutti i sensi del secondo termine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9090909090909091\n",
      "37\n"
     ]
    }
   ],
   "source": [
    "# Get max similarity between all synsets of two words, given a similarity function\n",
    "def get_max_similarity(s1, s2, sim_func):\n",
    "    s1_synsets = wn.synsets(s1)\n",
    "    s2_synsets = wn.synsets(s2)\n",
    "    max_sim = 0\n",
    "    # best_s1 = None\n",
    "    # best_s2 = None\n",
    "    for s1_syn in s1_synsets:\n",
    "        for s2_syn in s2_synsets:\n",
    "            sim = sim_func(s1_syn, s2_syn)\n",
    "            if sim > max_sim:\n",
    "                max_sim = sim\n",
    "                # best_s1 = s1_syn\n",
    "                # best_s2 = s2_syn\n",
    "    return max_sim\n",
    "\n",
    "\n",
    "# get lcs for dog and cat\n",
    "# print(get_lcs(wn.synset('cat.n.01'), wn.synset('cat.n.01')))\n",
    "print(get_max_similarity('love', 'sex', wup_sim))\n",
    "# print(depth(wn.synset('forecast.n.01')))\n",
    "# print(all_hypernyms(wn.synset('sexual_love.n.02')))\n",
    "# print(all_hypernyms(wn.synset('sex.n.01')))\n",
    "# print(lcs(wn.synset('sexual_love.n.02'), wn.synset('sex.n.01')))\n",
    "print(get_max_similarity('love', 'sex', short_path_sim))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('/Users/jak/Documents/Uni/TLN/TLN /Radicioni/data/WordSim353.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Word 1    Word 2  Human (mean)  wup_similarity  \\\n",
      "0            love       sex          6.77        0.909091   \n",
      "1           tiger       cat          7.35        0.962963   \n",
      "2           tiger     tiger         10.00        1.000000   \n",
      "3            book     paper          7.46        0.857143   \n",
      "4        computer  keyboard          7.62        0.800000   \n",
      "..            ...       ...           ...             ...   \n",
      "348        shower     flood          6.03        0.600000   \n",
      "349       weather  forecast          8.34        0.000000   \n",
      "350      disaster      area          6.25        0.428571   \n",
      "351      governor    office          6.34        0.470588   \n",
      "352  architecture   century          3.78        0.181818   \n",
      "\n",
      "     short_path_similarity  \n",
      "0                       37  \n",
      "1                       37  \n",
      "2                       38  \n",
      "3                       36  \n",
      "4                       35  \n",
      "..                     ...  \n",
      "348                     34  \n",
      "349                     25  \n",
      "350                     30  \n",
      "351                     29  \n",
      "352                     29  \n",
      "\n",
      "[353 rows x 5 columns]\n",
      "Wu and Palmer similarity results\n",
      "Spearman correlation: 0.32205979107230365, p-value: 5.816296751820106e-10\n",
      "Pearson correlation: 0.2756318557372003, p-value: 1.4205427728723012e-07\n",
      "--------------------------------\n",
      "Shortest Path similarity results\n",
      "Spearman correlation: 0.2725348694492164, p-value: 1.9812858428748427e-07\n",
      "Pearson correlation: 0.15778620904840207, p-value: 0.002952296149109044\n"
     ]
    }
   ],
   "source": [
    "# Prova la get_max_similarity su tutte le coppie di parole\n",
    "df['wup_similarity'] = df.apply(lambda row: get_max_similarity(row['Word 1'], row['Word 2'], wup_sim), axis=1)\n",
    "df['short_path_similarity'] = df.apply(lambda row: get_max_similarity(row['Word 1'], row['Word 2'], short_path_sim), axis=1)\n",
    "\n",
    "# Show the results\n",
    "print(df)\n",
    "\n",
    "# Results for Wu and Palmer similarity\n",
    "print('Wu and Palmer similarity results')\n",
    "spearman = stats.spearmanr(df['Human (mean)'], df['wup_similarity'])\n",
    "print(f'Spearman correlation: {spearman[0]}, p-value: {spearman[1]}')\n",
    "pearson = stats.pearsonr(df['Human (mean)'], df['wup_similarity'])\n",
    "print(f'Pearson correlation: {pearson[0]}, p-value: {pearson[1]}')\n",
    "\n",
    "print('--------------------------------')\n",
    "\n",
    "# Results for Shortest Path similarity\n",
    "print('Shortest Path similarity results')\n",
    "spearman = stats.spearmanr(df['Human (mean)'], df['short_path_similarity'])\n",
    "print(f'Spearman correlation: {spearman[0]}, p-value: {spearman[1]}')\n",
    "pearson = stats.pearsonr(df['Human (mean)'], df['short_path_similarity'])\n",
    "print(f'Pearson correlation: {pearson[0]}, p-value: {pearson[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get max similarity for each word pair from all synsets\n",
    "def get_max_similarity(word1, word2):\n",
    "    max_similarity = 0\n",
    "    for synset1 in wn.synsets(word1):\n",
    "        for synset2 in wn.synsets(word2):\n",
    "            similarity = synset1.path_similarity(synset2)\n",
    "            if similarity is not None and similarity > max_similarity:\n",
    "                max_similarity = similarity\n",
    "    return max_similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5587bf738ccec4bb524b17f914a1c07eb93a384af8fabdf9504251bc61fb6171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
