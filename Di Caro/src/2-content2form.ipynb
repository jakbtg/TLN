{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 2 - Content2Form\n",
    "\n",
    "In questo esercizio partendo dalle stesse definizioni date dagli studenti usate nell'esercizio 1, si vuole provare a inferire il miglior synset corrispondente a quelle definizioni.  \n",
    "Si tratta di **Onomasiologic search**.\n",
    "\n",
    "### Idea:\n",
    "- Esattamente come nell'esercizio 1, si salva l'input in un dizionario e si pulisce il dizionario\n",
    "- Si trovano le parole più frequenti per ogni lista di definizioni relative ad ogni termine (come nell'esercizio 1)\n",
    "- Si considerano le parole più frequenti come **genus** \n",
    "- Si preleva da wordnet synset name, definition e examples per *ogni* **iponimo** di ogni **genus**\n",
    "- Si sceglie il synset con la definizione più simile alla lista delle definizioni, ovvero con più parole in comune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leggi il file di input\n",
    "\n",
    "Salvo le varie definizioni degli studenti in un dizionario con:\n",
    "- chiave: parola (in ordine Emotion, Person, Revenge, Brick)\n",
    "- valore: lista di definizioni date dagli studenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/definizioni.xlsx')\n",
    "students = df.columns[1:].tolist()\n",
    "words = df[df.columns[0]].tolist()\n",
    "def_dict = {}\n",
    "for definition in words:\n",
    "    def_dict[definition] = []\n",
    "for student in students:\n",
    "    for definition in words:\n",
    "        def_dict[definition].append(df[student][df[df.columns[0]] == definition].values[0])\n",
    "\n",
    "# def_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ripulisci il dictionary delle definizioni\n",
    "\n",
    "Salvo le definizioni pulite in un dizionario strutturato come il precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# Tokenize and lemmatize definitions and remove stopwords and punctuation\n",
    "def clean_definitions(dict):\n",
    "    cleaned = dict.copy()\n",
    "    for key in cleaned:\n",
    "        definitions = [d for d in cleaned[key] if d == d]\n",
    "        tmp = []\n",
    "        for definition in definitions:\n",
    "            tmp.append([lemmatizer.lemmatize(token.lower()) for token in tokenizer.tokenize(definition) if token.lower() not in stopwords])\n",
    "        cleaned[key] = tmp\n",
    "    return cleaned\n",
    "\n",
    "clean_def_dict = clean_definitions(def_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trova i genus\n",
    "\n",
    "Per ogni parola, calcolo le *n* parole più frequenti nelle definizioni date dagli studenti, usando la funzione `most_common` di `Counter`.  \n",
    "Queste saranno considerate i **genus**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion [('feeling', 13), ('human', 8), ('feel', 8), ('something', 7), ('state', 5)]\n",
      "Person [('human', 29), ('person', 6), ('living', 4), ('individual', 3), ('certain', 3)]\n",
      "Revenge [('someone', 14), ('anger', 8), ('feeling', 7), ('action', 6), ('emotion', 6)]\n",
      "Brick [('used', 24), ('object', 16), ('material', 16), ('construction', 16), ('build', 13)]\n"
     ]
    }
   ],
   "source": [
    "# Get the most common words in the definitions of a word\n",
    "def get_common_words(dict, word, n):\n",
    "    words = []\n",
    "    for definition in dict[word]:\n",
    "        words += definition\n",
    "    return Counter(words).most_common(n)\n",
    "\n",
    "for word in clean_def_dict:\n",
    "    print(word, get_common_words(clean_def_dict, word, 5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trova tutti gli iponimi di ogni genus\n",
    "\n",
    "Per ogni genus, trovo tutti gli iponimi e salvo i loro nomi, definizioni e esempi in una lista ripulita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all hyponyms for all synsets of a word\n",
    "def find_hyponyms(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    hyponyms = []\n",
    "    for synset in synsets:\n",
    "        # hyponyms += synset.hyponyms() # Use this to get only direct hyponyms\n",
    "        hyponyms += synset.closure(lambda s:s.hyponyms()) # Use this to get all hyponyms\n",
    "    return set(hyponyms)\n",
    "\n",
    "# Save hyponyms name, definition and examples in a dictionary for a genus (frequent word)\n",
    "def get_genus_hypo_dict(word):\n",
    "    hyponyms = find_hyponyms(word)\n",
    "    hyponyms_dict = {}\n",
    "    for hyponym in hyponyms:\n",
    "        defs = hyponym.definition()\n",
    "        examples = hyponym.examples()\n",
    "        tmp = []\n",
    "        tmp.append(defs)\n",
    "        for example in examples:\n",
    "            tmp.append(example)\n",
    "        hyponyms_dict[hyponym.name()] = tmp\n",
    "\n",
    "    return hyponyms_dict\n",
    "\n",
    "# Preprocess hyponyms definition and examples\n",
    "def clean_hyponyms_dict(dict):\n",
    "    cleaned = dict.copy()\n",
    "    for key in cleaned:\n",
    "        for definition in cleaned[key]:\n",
    "            cleaned[key] = [lemmatizer.lemmatize(token.lower()) for token in tokenizer.tokenize(definition) if token.lower() not in stopwords]\n",
    "    return cleaned\n",
    "\n",
    "# hypo = get_genus_hypo_dict('human')\n",
    "# cleaned = clean_hyponyms_dict(hypo)\n",
    "# # print(hypo)\n",
    "# print(cleaned)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trova il synset più simile alle definizioni\n",
    "\n",
    "Per ogni iponimo, calcolo la similarità tra la lista delle definizioni date dagli studenti e la definizione dell'iponimo.  \n",
    "La similarità è calcolata come il numero di parole in comune tra le due liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word: Emotion\n",
      "3 most frequent words: ['feeling', 'human', 'feel']\n",
      "Most similar synset: hate.n.01 with a similarity of 4\n",
      "Coming from genus: feeling\n",
      "hate.n.01: the emotion of intense dislike; a feeling of dislike so strong that it demands action\n",
      "\n",
      "Word: Person\n",
      "3 most frequent words: ['human', 'person', 'living']\n",
      "Most similar synset: homo_sapiens.n.01 with a similarity of 4\n",
      "Coming from genus: human\n",
      "homo_sapiens.n.01: the only surviving hominid; species to which modern man belongs; bipedal primate having language and ability to make and use complex tools; brain volume at least 1400 cc\n",
      "\n",
      "Word: Revenge\n",
      "3 most frequent words: ['someone', 'anger', 'feeling']\n",
      "Most similar synset: motile.n.01 with a similarity of 6\n",
      "Coming from genus: someone\n",
      "motile.n.01: one whose prevailing mental imagery takes the form of inner feelings of action\n",
      "\n",
      "Word: Brick\n",
      "3 most frequent words: ['used', 'object', 'material']\n",
      "Most similar synset: brick.n.01 with a similarity of 6\n",
      "Coming from genus: object\n",
      "brick.n.01: rectangular block of clay baked by the sun or in a kiln; used as a building or paving material\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Compute the similarity between the list of definitions of a word and the definition of a hyponym as the number of common words\n",
    "# def compute_similarity(def_dict, word, hyponym, cleaned_hypo_dict):\n",
    "#     similarity = 0\n",
    "#     for definition in def_dict[word]:\n",
    "#         for word in definition:\n",
    "#             if word in cleaned_hypo_dict[hyponym]:\n",
    "#                 # print(f'Definition: {definition}')\n",
    "#                 # print(f'Hyponym name: {hyponym}')\n",
    "#                 # print(f'Common word: {word}')\n",
    "#                 similarity += 1\n",
    "#     return similarity\n",
    "\n",
    "def compute_similarity(def_dict, word, hyponym, cleaned_hypo_dict):\n",
    "    similarity = 0\n",
    "    set_def_words = set()\n",
    "    for definition in def_dict[word]:\n",
    "        for word in definition:\n",
    "            set_def_words.add(word)\n",
    "    set_hypo_words = set()\n",
    "    for word in cleaned_hypo_dict[hyponym]:\n",
    "        set_hypo_words.add(word)\n",
    "    similarity = len(set_def_words.intersection(set_hypo_words))\n",
    "    return similarity\n",
    "\n",
    "# Find the most similar hyponym computing the similarity for all hyponyms\n",
    "def find_most_similar_hypo(def_dict, word, cleaned_hypo_dict):\n",
    "    most_similar = ''\n",
    "    max_similarity = 0\n",
    "    for hypo in cleaned_hypo_dict:\n",
    "        similarity = compute_similarity(def_dict, word, hypo, cleaned_hypo_dict)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar = hypo\n",
    "    # most_similar = most_similar.split('.')[0]\n",
    "    return most_similar, max_similarity\n",
    "\n",
    "# Find the most similar hyponym from all genus (frequent words)\n",
    "def find_synset(def_dict, word, n):\n",
    "    freq_words = get_common_words(def_dict, word, n)\n",
    "    freqs = []\n",
    "    syn = ''\n",
    "    max_similarity = 0\n",
    "    winning_genus = ''\n",
    "    for freq in freq_words:\n",
    "        freqs.append(freq[0])\n",
    "        hypos = get_genus_hypo_dict(freq[0])\n",
    "        hypo_cleaned = clean_hyponyms_dict(hypos)\n",
    "        hypo, similarity = find_most_similar_hypo(def_dict, word, hypo_cleaned)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            syn = hypo\n",
    "            winning_genus = freq[0]\n",
    "    return syn, max_similarity, freqs, winning_genus\n",
    "\n",
    "for key in clean_def_dict:\n",
    "    n_freqs = 3\n",
    "    syn, similarity, freqs, winning = find_synset(clean_def_dict, key, n_freqs)\n",
    "    print(f'Word: {key}')\n",
    "    print(f'{n_freqs} most frequent words: {freqs}')\n",
    "    print(f'Most similar synset: {syn} with a similarity of {similarity}')\n",
    "    print(f'Coming from genus: {winning}')\n",
    "    print(f'{syn}: {wn.synset(syn).definition()}')\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5587bf738ccec4bb524b17f914a1c07eb93a384af8fabdf9504251bc61fb6171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
