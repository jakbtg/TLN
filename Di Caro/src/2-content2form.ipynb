{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 2 - Content2Form\n",
    "\n",
    "In questo esercizio partendo dalle stesse definizioni date dagli studenti usate nell'esercizio 1, si vuole provare a inferire il miglior synset corrispondente a quelle definizioni.  \n",
    "Si tratta di **Onomasiologic search**.\n",
    "\n",
    "### Idea:\n",
    "- Esattamente come nell'esercizio 1, si salva l'input in un dizionario e si pulisce il dizionario\n",
    "- Si trovano le parole più frequenti per ogni lista di definizioni relative ad ogni termine (come nell'esercizio 1)\n",
    "- Si considerano le parole più frequenti come **genus** \n",
    "- Si preleva da wordnet synset name, definition e examples per *ogni* **iponimo** di ogni **genus**\n",
    "- Si sceglie il synset con la definizione più simile alla lista delle definizioni, ovvero con più parole in comune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter\n",
    "from nltk.corpus import wordnet as wn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leggi il file di input\n",
    "\n",
    "Salvo le varie definizioni degli studenti in un dizionario con:\n",
    "- chiave: parola (in ordine Emotion, Person, Revenge, Brick)\n",
    "- valore: lista di definizioni date dagli studenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/definizioni.xlsx')\n",
    "students = df.columns[1:].tolist()\n",
    "words = df[df.columns[0]].tolist()\n",
    "def_dict = {}\n",
    "for definition in words:\n",
    "    def_dict[definition] = []\n",
    "for student in students:\n",
    "    for definition in words:\n",
    "        def_dict[definition].append(df[student][df[df.columns[0]] == definition].values[0])\n",
    "\n",
    "# def_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ripulisci il dictionary delle definizioni\n",
    "\n",
    "Salvo le definizioni pulite in un dizionario strutturato come il precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# Tokenize and lemmatize definitions and remove stopwords and punctuation\n",
    "def clean_definitions(dict):\n",
    "    cleaned = dict.copy()\n",
    "    for key in cleaned:\n",
    "        definitions = [d for d in cleaned[key] if d == d]\n",
    "        tmp = []\n",
    "        for definition in definitions:\n",
    "            tmp.append([lemmatizer.lemmatize(token.lower()) for token in tokenizer.tokenize(definition) if token.lower() not in stopwords])\n",
    "        cleaned[key] = tmp\n",
    "    return cleaned\n",
    "\n",
    "clean_def_dict = clean_definitions(def_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trova i genus\n",
    "\n",
    "Per ogni parola, calcolo le *n* parole più frequenti nelle definizioni date dagli studenti, usando la funzione `most_common` di `Counter`.  \n",
    "Queste saranno considerate i **genus**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emotion [('feeling', 13), ('human', 8), ('feel', 8), ('something', 7), ('state', 5)]\n",
      "Person [('human', 29), ('person', 6), ('living', 4), ('individual', 3), ('certain', 3)]\n",
      "Revenge [('someone', 14), ('anger', 8), ('feeling', 7), ('action', 6), ('emotion', 6)]\n",
      "Brick [('used', 24), ('object', 16), ('material', 16), ('construction', 16), ('build', 13)]\n"
     ]
    }
   ],
   "source": [
    "# Get the most common words in the definitions of a word\n",
    "def get_common_words(dict, word, n):\n",
    "    words = []\n",
    "    for definition in dict[word]:\n",
    "        words += definition\n",
    "    return Counter(words).most_common(n)\n",
    "\n",
    "for word in clean_def_dict:\n",
    "    print(word, get_common_words(clean_def_dict, word, 5))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trova tutti gli iponimi di ogni genus\n",
    "\n",
    "Per ogni genus, trovo tutti gli iponimi e salvo i loro nomi, definizioni e esempi in una lista ripulita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'java_man.n.01': ['fossil', 'remains', 'found', 'java', 'formerly', 'called', 'pithecanthropus', 'erectus'], 'boskop_man.n.01': ['possible', 'early', 'homo', 'sapiens', 'represented', 'cranium', 'found', 'transvaal', 'formerly', 'considered', 'separate', 'specie'], 'neandertal_man.n.01': ['extinct', 'robust', 'human', 'middle', 'paleolithic', 'europe', 'western', 'asia'], 'homo_erectus.n.01': ['homo', 'erectus', 'formerly', 'called', 'pithecanthropus', 'erectus'], 'homo_sapiens_sapiens.n.01': ['subspecies', 'homo', 'sapiens', 'includes', 'modern', 'race'], 'world.n.08': ['always', 'used', 'humankind', 'mankind', 'seemed', 'slight', 'woman'], 'rhodesian_man.n.01': ['primitive', 'hominid', 'resembling', 'neanderthal', 'man', 'living', 'africa'], 'peking_man.n.01': ['fossil', 'found', 'near', 'beijing', 'china', 'lost', 'world', 'war', 'ii'], 'solo_man.n.01': ['early', 'man', 'late', 'pleistocene', 'skull', 'resembles', 'neanderthal', 'man', 'smaller', 'cranial', 'capacity', 'found', 'java'], 'homo_soloensis.n.01': ['extinct', 'primitive', 'hominid', 'late', 'pleistocene', 'java', 'formerly', 'javanthropus'], 'homo_sapiens.n.01': ['surviving', 'hominid', 'specie', 'modern', 'man', 'belongs', 'bipedal', 'primate', 'language', 'ability', 'make', 'use', 'complex', 'tool', 'brain', 'volume', 'least', '1400', 'cc'], 'homo_habilis.n.01': ['extinct', 'specie', 'upright', 'east', 'african', 'hominid', 'advanced', 'humanlike', 'characteristic'], 'cro-magnon.n.01': ['extinct', 'human', 'upper', 'paleolithic', 'europe']}\n"
     ]
    }
   ],
   "source": [
    "# Find all hyponyms for all synsets of a word\n",
    "def find_hyponyms(word):\n",
    "    synsets = wn.synsets(word)\n",
    "    hyponyms = []\n",
    "    for synset in synsets:\n",
    "        # hyponyms += synset.hyponyms()\n",
    "        # Closure is used to get all hyponyms for all direct hyponyms\n",
    "        hyponyms += synset.closure(lambda s:s.hyponyms())\n",
    "    return set(hyponyms)\n",
    "\n",
    "# Save hyponyms name, definition and examples in a dictionary\n",
    "def get_hyponyms_dict(word):\n",
    "    hyponyms = find_hyponyms(word)\n",
    "    hyponyms_dict = {}\n",
    "    for hyponym in hyponyms:\n",
    "        defs = hyponym.definition()\n",
    "        examples = hyponym.examples()\n",
    "        tmp = []\n",
    "        tmp.append(defs)\n",
    "        for example in examples:\n",
    "            tmp.append(example)\n",
    "        hyponyms_dict[hyponym.name()] = tmp\n",
    "\n",
    "    return hyponyms_dict\n",
    "\n",
    "# Preprocess hyponyms definition and examples\n",
    "def clean_hyponyms_dict(dict):\n",
    "    cleaned = dict.copy()\n",
    "    for key in cleaned:\n",
    "        for definition in cleaned[key]:\n",
    "            cleaned[key] = [lemmatizer.lemmatize(token.lower()) for token in tokenizer.tokenize(definition) if token.lower() not in stopwords]\n",
    "    return cleaned\n",
    "\n",
    "hypo = get_hyponyms_dict('human')\n",
    "cleaned = clean_hyponyms_dict(hypo)\n",
    "# print(hypo)\n",
    "print(cleaned)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trova il synset più simile alle definizioni\n",
    "\n",
    "Per ogni iponimo, calcolo la similarità tra la lista delle definizioni date dagli studenti e la definizione dell'iponimo.  \n",
    "La similarità è calcolata come il numero di parole in comune tra le due liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feeling', 'human', 'feel', 'something']\n",
      "['resentment.n.01', 'conflict.n.02', 'addiction.n.02', 'pensiveness.n.01', 'smugness.n.01', 'pruritus_ani.n.01', 'exhilaration.n.01', 'anaphrodisia.n.01', 'pet.n.03', 'anglophobia.n.01', 'eagerness.n.01', 'self-disgust.n.01', 'misoneism.n.01', 'languor.n.01', 'anxiousness.n.02', 'insecurity.n.02', 'loyalty.n.02', 'disgust.n.01', 'timidity.n.01', 'displeasure.n.01', 'ambition.n.01', 'warpath.n.01', 'stupefaction.n.01', 'unassertiveness.n.01', 'pride.n.02', 'agony.n.01', 'happiness.n.01', 'first_blush.n.01', 'steam.v.04', 'anguish.v.01', 'exuberance.n.01', 'warmheartedness.n.01', 'hysteria.n.02', 'misocainea.n.01', 'emotionlessness.n.01', 'stir.n.02', 'testiness.n.01', 'radiance.n.03', 'belligerence.n.01', 'cheer.v.04', 'surprise.n.01', 'compatibility.n.01', 'self-pity.n.01', 'heaviness.n.02', 'worship.n.02', 'schadenfreude.n.01', 'peeve.n.01', 'hesitance.n.01', 'ill_humor.n.01', 'horror.n.01', 'fondness.n.01', 'longing.n.01', 'thing.n.11', 'topognosia.n.01', 'intoxication.n.03', 'easiness.n.01', 'trepidation.n.01', 'unhappiness.n.02', 'zeitgeist.n.01', 'fidget.n.01', 'conditioned_emotional_response.n.01', 'despondency.n.01', 'joie_de_vivre.n.01', 'broken_heart.n.01', 'self-depreciation.n.01', 'hollywood.n.02', 'dolor.n.01', 'swivet.n.01', 'fetish.n.01', 'leaning.n.01', 'buck_fever.n.01', 'bonheur.n.01', 'diffidence.n.01', 'commiseration.n.01', 'discontentment.n.01', 'discomfiture.n.01', 'temper.n.02', 'nymphomania.n.01', 'lighten.v.03', 'hate.n.01', 'fume.v.01', 'nirvana.n.01', 'heavyheartedness.n.01', 'wishfulness.n.01', 'frustration.n.01', 'commiserate.v.01', 'forgiveness.n.01', 'abashment.n.01', 'ego.n.01', 'brotherhood.n.03', 'discouragement.n.01', 'hankering.n.01', 'fatigue.n.03', 'ardor.n.03', 'wallow.v.04', 'annoyance.n.02', 'self-consciousness.n.01', 'woe.n.02', 'scare.n.02', 'prurience.n.01', 'amour_propre.n.01', 'calmness.n.03', 'satyriasis.n.01', 'dysphoria.n.01', 'shamefacedness.n.01', 'animosity.n.01', 'euphoria.n.01', 'chill.n.04', 'optimism.n.01', 'tsoris.n.01', 'demoralization.n.03', 'poignance.n.01', 'anger.v.02', 'foreboding.n.01', 'melancholy.n.01', 'take_pride.v.01', 'joy.n.01', 'puppy_love.n.01', 'enjoyment.n.01', 'aphrodisia.n.01', 'grudge.n.01', 'sorrow.n.01', 'jocundity.n.01', 'attrition.n.03', 'quality_of_life.n.01', 'love.n.04', 'grieve.v.01', 'passion.n.01', 'nationalism.n.03', 'intimidation.n.03', 'wound.n.03', 'silver_lining.n.01', 'razbliuto.n.01', 'gaiety.n.02', 'forlornness.n.01', 'harbor.v.01', 'weakness.n.05', 'withdrawal.n.04', 'worry.n.02', 'aggression.n.02', 'sadden.v.02', 'shyness.n.01', 'suffer.v.03', 'benevolence.n.01', 'feel_for.v.01', 'stewing.n.01', 'meekness.n.01', 'craving.n.01', 'die.v.05', 'sensuousness.n.01', 'repentance.n.01', 'distance.n.04', 'concern.n.02', 'amusement.n.01', 'pleasantness.n.01', 'cold_comfort.n.01', 'gladden.v.02', 'joylessness.n.01', 'good_will.n.03', 'heart.n.01', 'solicitude.n.01', 'isolation.n.02', 'hostility.n.03', 'downheartedness.n.01', 'disinclination.n.01', 'hope.n.01', 'scunner.n.01', 'inferiority_complex.n.01', 'tenderness.n.03', 'pang.n.01', 'misogyny.n.01', 'dudgeon.n.01', 'cheerlessness.n.01', 'creepiness.n.01', 'gloat.n.01', 'dissatisfaction.n.01', 'intuition.n.02', 'libido.n.01', 'american_dream.n.01', 'repugnance.n.01', 'amorousness.n.02', 'happiness.n.02', 'tranquillity.n.02', 'levity.n.01', 'temptation.n.02', 'state.n.06', 'guilt_pang.n.01', 'regard.n.06', 'emotional_state.n.01', 'sexual_desire.n.01', 'creepy-crawlies.n.01', 'survivor_guilt.n.01', 'astonishment.n.01', 'admiration.n.01', 'pining.n.01', 'sadness.n.01', 'belonging.n.01', 'togetherness.n.01', 'fly_high.v.01', 'sexual_pleasure.n.01', 'plaintiveness.n.01', 'technophobia.n.01', 'smolder.v.02', 'scruple.n.02', 'agitation.n.03', 'gratefulness.n.01', 'chagrin.n.01', 'agape.n.01', 'blahs.n.01', 'homesickness.n.01', 'cold_feet.n.01', 'antipathy.n.01', 'electra_complex.n.01', 'friendliness.n.01', 'glow.v.05', 'shame.n.01', 'urtication.n.02', 'favor.n.04', 'comfort.n.05', 'anxiety.n.02', 'caprice.n.01', 'peace.n.03', 'passion.n.05', 'self-torture.n.01', 'sadness.n.02', 'oppression.n.03', 'preference.n.01', 'gravity.n.03', 'suspense.n.03', 'cool_off.v.03', 'fury.n.01', 'misology.n.01', 'fever.n.02', 'rejoice.v.01', 'approbation.n.01', 'misery.n.02', 'earnestness.n.01', 'gold_fever.n.01', 'exuberate.v.01', 'triumph.n.02', 'protectiveness.n.01', 'covetousness.n.01', 'pruritus.n.01', 'appetite.n.01', 'stomach.n.04', 'sympathy.n.02', 'disapproval.n.01', 'fearlessness.n.01', 'stage_effect.n.01', 'beneficence.n.01', 'enthusiasm.n.01', 'sensitivity.n.03', 'maleficence.n.01', 'compassion.n.01', 'approval.n.02', 'anger.n.01', 'love.n.01', 'closeness.n.01', 'presage.n.01', 'sound_effect.n.01', 'wildness.n.01', 'sentimentality.n.02', 'discomfort.n.02', 'umbrage.n.01', 'delight.n.01', 'resignation.n.01', 'tickle.n.01', 'guilt.n.02', 'misogamy.n.01', 'pruritus_vulvae.n.01', 'sulk.n.01', 'entrancement.n.01', 'gratification.n.01', 'pessimism.n.01', 'cutaneous_sensation.n.01', 'affect.n.01', 'heartlessness.n.01', 'gusto.n.01', 'oversensitiveness.n.01', 'unrest.n.02', 'dignity.n.01', 'buoyancy.n.01', 'hero_worship.n.01', 'envy.n.01', 'moodiness.n.01', 'alienation.n.01', 'blessedness.n.01', 'aggravation.n.01', 'class_feeling.n.01', 'captivation.n.02', 'languor.n.02', 'antagonism.n.03', 'irritability.n.01', 'infatuation.n.01', 'carefreeness.n.01', 'constriction.n.03', 'grief.n.01', 'edginess.n.01', 'itch.n.03', 'jitteriness.n.01', 'civic_pride.n.01', 'good_humor.n.01', 'humility.n.02', 'suffering.n.04', 'afterglow.n.02', 'creeps.n.02', 'sweet_tooth.n.01', 'cruelty.n.02', 'angst.n.01', 'contempt.n.01', 'ambivalence.n.01', 'irascibility.n.01', 'sinking.n.03', 'dolefulness.n.01', 'throes.n.01', 'weepiness.n.01', 'confidence.n.02', 'satisfaction.n.01', 'bloodlust.n.01', 'frisson.n.01', 'emotion.n.01', 'impatience.n.02', 'anguish.n.01', 'daze.n.01', 'devotion.n.01', 'glory.v.01', 'misanthropy.n.01', 'sanguinity.n.01', 'moroseness.n.01', 'panic.n.01', 'sprachgefuhl.n.01', 'complacency.n.01', 'sensation.n.03', 'boredom.n.01', 'pleasure.n.01', 'wonder.n.01', 'ingratitude.n.01', 'presence.n.04', 'masochism.n.01', 'pain.n.02', 'philogyny.n.01', 'hope.n.02', 'storminess.n.02', 'sentiment.n.01', 'embarrassment.n.02', 'elation.n.02', 'stage_fright.n.01', 'mental_anguish.n.01', 'sorrow.n.02', 'awe.n.01', 'nausea.n.02', 'encouragement.n.03', 'rejoicing.n.01', 'defeatism.n.01', 'feel_like_a_million.v.01', 'desire.n.01', 'cynicism.n.01', 'frustration.n.03', 'lose.v.03', 'emulation.n.01', 'inclination.n.05', 'ardor.n.01', 'titillation.n.01', 'indignation.n.01', 'raise_the_roof.v.01', 'velleity.n.01', 'ardor.n.02', 'suspense.n.01', 'burn.v.06', 'care.v.01', 'empathy.n.01', 'mercifulness.n.01', 'disgruntlement.n.01', 'pique.n.02', 'cheerfulness.n.02', 'grope_for.v.01', 'mellowness.n.01', 'crawl.v.02', 'despair.n.02', 'tumult.n.02', 'unfriendliness.n.01', 'sadism.n.01', 'gloom.n.02', 'urge.n.02', 'nostalgia.n.01', 'helplessness.n.03', 'sympathize.v.01', 'devastation.n.02', 'harassment.n.01', 'alarm.n.01', 'sulkiness.n.02', 'dander.n.02', 'amorousness.n.01', 'penis_envy.n.01', 'malice.n.01', 'mourn.v.01', 'affection.n.01', 'wrath.n.01', 'mysophilia.n.01', 'concern.n.03', 'relief.n.01', 'gladness.n.01', 'electricity.n.03', 'soft_spot.n.02', 'malevolence.n.01', 'misopedia.n.01', 'bad_temper.n.01', 'filial_love.n.01', 'world-weariness.n.01', 'conscience.n.03', 'technophilia.n.01', 'indifference.n.01', 'unpleasantness.n.01', 'mawkishness.n.01', 'lovesickness.n.01', 'sex.n.03', 'exultation.n.01', 'compunction.n.01', 'chafe.v.02', 'bang.n.04', 'algolagnia.n.01', 'heartburning.n.01', 'willies.n.01', 'depression.n.04', 'mournfulness.n.01', 'embarrassment.n.01', 'glow.n.04', 'sensibility.n.02', 'incline.v.05', 'insight.n.02', 'gratitude.n.01', 'placidity.n.01', 'murderousness.n.01', 'security.n.03', 'lecherousness.n.01', 'condole.v.01', 'despisal.n.01', 'fulfillment.n.01', 'agonize.v.02', 'apprehension.n.01', 'comfortableness.n.02', 'recapture.v.01', 'heartstrings.n.01', 'stomach.n.03', 'confusion.n.03', 'embitterment.n.01', 'bridle.v.01', 'wish.n.01', 'feelings.n.01', 'jollity.n.01', 'distress.n.01', 'infuriation.n.01', 'pride.v.01', 'consolation.n.01', 'hopelessness.n.01', 'amicability.n.01', 'comfort.n.02', 'weight.n.05', 'anticipation.n.01', 'soul.n.03', 'sadomasochism.n.01', 'dislike.n.02', 'mourning.n.01', 'shadow.n.04', 'effect.n.03', 'exult.v.01', 'acquired_taste.n.01', 'sensuality.n.01', 'huffiness.n.01', 'apathy.n.01', 'attachment.n.01', 'lovingness.n.01', 'disappointment.n.01', 'coolness.n.01', 'faintness.n.01', 'special_effect.n.01', 'complex.n.03', 'the_hots.n.01', 'philhellenism.n.01', 'contentment.n.01', 'liking.n.01', 'intimidation.n.02', 'hilarity.n.01', 'oedipus_complex.n.01', 'expectation.n.03', 'pride.n.01', 'repent.v.02', 'ecstasy.n.01', 'abhorrence.n.01', 'wistfulness.n.01', 'jealousy.n.01', 'undertow.n.01', 'anglophilia.n.01', 'fear.n.01', 'fear.n.03', 'growing_pains.n.02', 'glow.v.04', 'zeal.n.02', 'kindheartedness.n.01', 'hopefulness.n.02', 'agape.n.02', 'fit.n.01', 'lividity.n.01', 'vindictiveness.n.01', 'unconcern.n.02', 'softheartedness.n.01', 'suffocate.v.06', 'self-esteem.n.01', 'gaiety.n.01', 'java_man.n.01', 'boskop_man.n.01', 'neandertal_man.n.01', 'homo_erectus.n.01', 'homo_sapiens_sapiens.n.01', 'world.n.08', 'rhodesian_man.n.01', 'peking_man.n.01', 'solo_man.n.01', 'homo_soloensis.n.01', 'homo_sapiens.n.01', 'homo_habilis.n.01', 'cro-magnon.n.01', 'fly_high.v.01', 'crawl.v.02', 'chafe.v.02', 'gladden.v.02', 'sandiness.n.01', 'wallow.v.04', 'french_polish.n.01', 'pride.v.01', 'coarseness.n.03', 'sympathize.v.01', 'polish.n.01', 'hollywood.n.02', 'cool_off.v.03', 'smolder.v.02', 'touch.n.12', 'fineness.n.03', 'harshness.n.01', 'repent.v.02', 'cheer.v.04', 'grieve.v.01', 'glaze.n.02', 'rejoice.v.01', 'coarseness.n.02', 'smoothness.n.01', 'exuberate.v.01', 'nap.n.02', 'mourn.v.01', 'feel_like_a_million.v.01', 'harbor.v.01', 'incline.v.05', 'lose.v.03', 'texture.n.01', 'glory.v.01', 'roughness.n.01', 'scaliness.n.01', 'raise_the_roof.v.01', 'prickliness.n.01', 'sadden.v.02', 'burn.v.06', 'lighten.v.03', 'suffer.v.03', 'slub.n.01', 'fume.v.01', 'glow.v.05', 'care.v.01', 'feel_for.v.01', 'exult.v.01', 'shagginess.n.02', 'glow.v.04', 'steam.v.04', 'slickness.n.03', 'silkiness.n.01', 'die.v.05', 'condole.v.01', 'agonize.v.02', 'bumpiness.n.01', 'commiserate.v.01', 'zeitgeist.n.01', 'anger.v.02', 'suffocate.v.06', 'recapture.v.01', 'grope_for.v.01', 'take_pride.v.01', 'anguish.v.01', 'bridle.v.01']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'copy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vy/61q2hg6j75vdf08b96dmw_6c0000gn/T/ipykernel_21794/3962276352.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0mhypos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyponyms_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m \u001b[0mhypo_cleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_hyponyms_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypo_cleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/vy/61q2hg6j75vdf08b96dmw_6c0000gn/T/ipykernel_21794/3962276352.py\u001b[0m in \u001b[0;36mclean_hyponyms_list\u001b[0;34m(list)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0mcleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mcleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_hyponyms_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/vy/61q2hg6j75vdf08b96dmw_6c0000gn/T/ipykernel_21794/38665553.py\u001b[0m in \u001b[0;36mclean_hyponyms_dict\u001b[0;34m(dict)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# Preprocess hyponyms definition and examples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mclean_hyponyms_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m     \u001b[0mcleaned\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdefinition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcleaned\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'copy'"
     ]
    }
   ],
   "source": [
    "# Compute the similarity between the list of definitions of a word and the definition of a hyponym as the number of common words\n",
    "def compute_similarity(def_dict, word, hyponym, cleaned_hypo_dict):\n",
    "    similarity = 0\n",
    "    for definition in def_dict[word]:\n",
    "        for word in definition:\n",
    "            if word in cleaned_hypo_dict[hyponym]:\n",
    "                # print(f'Definition: {definition}')\n",
    "                # print(f'Hyponym name: {hyponym}')\n",
    "                # print(f'Common word: {word}')\n",
    "                similarity += 1\n",
    "    return similarity\n",
    "\n",
    "# Find the most similar hyponym computing the similarity for all hyponyms\n",
    "def find_most_similar_hypo(def_dict, word, cleaned_hypo_dict):\n",
    "    most_similar = ''\n",
    "    max_similarity = 0\n",
    "    for hypo in cleaned_hypo_dict:\n",
    "        similarity = compute_similarity(def_dict, word, hypo, cleaned_hypo_dict)\n",
    "        if similarity > max_similarity:\n",
    "            max_similarity = similarity\n",
    "            most_similar = hypo\n",
    "    # most_similar = most_similar.split('.')[0]\n",
    "    return most_similar, max_similarity\n",
    "\n",
    "# Get all hyponyms dicts for a list of words\n",
    "def hyponyms_list(list):\n",
    "    hyponyms = []\n",
    "    for word in list:\n",
    "        hyponyms += get_hyponyms_dict(word)\n",
    "    return hyponyms\n",
    "\n",
    "# Clean a list of hypo dicts\n",
    "def clean_hyponyms_list(list):\n",
    "    cleaned = list.copy()\n",
    "    for i in range(len(cleaned)):\n",
    "        cleaned[i] = clean_hyponyms_dict(cleaned[i])\n",
    "    return cleaned\n",
    "\n",
    "# Find the most similar hyponym for all words\n",
    "# def find_most_similar_hyponyms(dict):\n",
    "#     most_similar = {}\n",
    "#     for word in dict:\n",
    "#         most_similar[word] = find_most_similar_syn(dict, word)\n",
    "#     return most_similar\n",
    "\n",
    "\n",
    "# for word in clean_def_dict:\n",
    "#     freq_words = get_common_words(clean_def_dict, word, 2)\n",
    "#     print(word, freq_words)\n",
    "#     for freq_word in freq_words:\n",
    "#         print(freq_word[0], find_most_similar_hyponym(clean_def_dict, freq_word[0]))\n",
    "word = 'Emotion'\n",
    "freq_words = get_common_words(clean_def_dict, word, 4)\n",
    "freqs = []\n",
    "for freq in freq_words: \n",
    "    freqs.append(freq[0])\n",
    "print(freqs)\n",
    "hypos = hyponyms_list(freqs)\n",
    "print(hypos)\n",
    "hypo_cleaned = clean_hyponyms_list(hypos)\n",
    "print(hypo_cleaned)\n",
    "\n",
    "# hypo_cleaned = clean_hyponyms_dict(hypos)\n",
    "# print(hypo_cleaned)\n",
    "# for hypo in hypo_cleaned:\n",
    "#     print(compute_similarity(clean_def_dict, word, hypo, hypo_cleaned))\n",
    "# print(find_most_similar_hypo(clean_def_dict, word, hypo_cleaned))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5587bf738ccec4bb524b17f914a1c07eb93a384af8fabdf9504251bc61fb6171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
