{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 4 - Segmentation\n",
    "\n",
    "- Implementare un semplice algoritmo di text segmentation\n",
    "- Usare come test un input di k paragrafi presi da differenti temi (ad es. pagine Wikipedia)  \n",
    "- Il vostro sistema è in grado di trovare i giusti “tagli”?\n",
    "\n",
    "## Idea:\n",
    "\n",
    "- Ripulisco il file di testo da stopwords e punteggiatura e lo tokenizzo e lemmatizzo, ottenendo una lista di relevant words\n",
    "- Suddivido il file di input in una lista di liste: ogni riga del file di input diventa una lista di relevant words\n",
    "- Calcolo la cosine similarity tra ogni riga del file di input e la riga successiva\n",
    "- Posiziono i tagli nei punti di minimo della cosine similarity\n",
    "\n",
    "\n",
    "## File di input\n",
    "\n",
    "Come file di input uso un file di testo contenente un po' di paragrafi presi da Wikipedia riguardo a 4 argomenti diversi:\n",
    "- Lebanon\n",
    "- Racing bike\n",
    "- Labrador retriever\n",
    "- Indie rock  \n",
    "\n",
    "I tagli che dovrebbe trovare il mio algoritmo sono alla linea 27-28, alla linea 58-59 e alla linea 97-98.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing del file di input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "with open('../data/wiki.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        data.append(line.strip())\n",
    "    \n",
    "lemmatizer = WordNetLemmatizer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "stop_words = stopwords.words('english')\n",
    "paragraphs = []\n",
    "for line in data:\n",
    "    words = [lemmatizer.lemmatize(token.lower()) for token in tokenizer.tokenize(line) if token.lower() not in stop_words] \n",
    "    paragraphs.append(words)\n",
    "\n",
    "# paragraphs[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creo una lista di tutte le relevant words del file di input, rimuovendo i duplicati ma mantenendo l'ordine "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of all words with duplicates\n",
    "all_words = []\n",
    "for paragraph in paragraphs:\n",
    "    for word in paragraph:\n",
    "        all_words.append(word)\n",
    "\n",
    "# Remove duplicates but keep the order\n",
    "all_words = list(dict.fromkeys(all_words))\n",
    "# all_words\n",
    "\n",
    "# all_words = list(all_words)\n",
    "# all_words_dict = {word: i for i, word in enumerate(all_words)}\n",
    "# all_words_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creo un dizionario per ogni paragrafo del file di input, dove la chiave è la parola e il valore la sua frequenza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of all words in one paragraph\n",
    "def paragraph_dict(p1):\n",
    "    paragraph_dict = {}\n",
    "    for word in all_words:\n",
    "        paragraph_dict[word] = 0\n",
    "    for word in p1:\n",
    "        paragraph_dict[word] += 1\n",
    "    return paragraph_dict\n",
    "\n",
    "# # Create a dictionary of all words in two paragraphs\n",
    "# def paragraph_dict(p1, p2):\n",
    "#     paragraph_dict = {}\n",
    "#     for word in all_words:\n",
    "#         paragraph_dict[word] = 0\n",
    "#     for word in p1:\n",
    "#         paragraph_dict[word] += 1\n",
    "#     for word in p2:\n",
    "#         paragraph_dict[word] += 1\n",
    "#     return paragraph_dict\n",
    "\n",
    "# From the dictionary create a list of word counts\n",
    "def paragraph_list(paragraph_dict):\n",
    "    paragraph_list = []\n",
    "    for word in all_words:\n",
    "        paragraph_list.append(paragraph_dict[word])\n",
    "    return paragraph_list\n",
    "\n",
    "# par1 = paragraphs[0]\n",
    "# par2 = paragraphs[1]\n",
    "# # par_dict = paragraph_dict(par1, par2)\n",
    "# par_dict = paragraph_dict(par1)\n",
    "# par_list = paragraph_list(par_dict)\n",
    "# print(par_dict)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo della cosine similarity tra ogni riga del file di input e la riga successiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Paragraphs 1 and 2 are similar with a cosine similarity of [[0.18761766]]\n",
      "Paragraphs 2 and 3 are similar with a cosine similarity of [[0.31999903]]\n",
      "Paragraphs 3 and 4 are similar with a cosine similarity of [[0.24628353]]\n",
      "Paragraphs 4 and 5 are similar with a cosine similarity of [[0.06278421]]\n",
      "Paragraphs 5 and 6 are similar with a cosine similarity of [[0.20894948]]\n",
      "Paragraphs 6 and 7 are similar with a cosine similarity of [[0.315353]]\n",
      "Paragraphs 7 and 8 are similar with a cosine similarity of [[0.63245553]]\n",
      "Paragraphs 8 and 9 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 9 and 10 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 10 and 11 are similar with a cosine similarity of [[0.11899932]]\n",
      "Paragraphs 11 and 12 are similar with a cosine similarity of [[0.17242311]]\n",
      "Paragraphs 12 and 13 are similar with a cosine similarity of [[0.11624764]]\n",
      "Paragraphs 13 and 14 are similar with a cosine similarity of [[0.21213203]]\n",
      "Paragraphs 14 and 15 are similar with a cosine similarity of [[0.11547005]]\n",
      "Paragraphs 15 and 16 are similar with a cosine similarity of [[0.02282177]]\n",
      "Paragraphs 16 and 17 are similar with a cosine similarity of [[0.08588975]]\n",
      "Paragraphs 17 and 18 are similar with a cosine similarity of [[0.0959677]]\n",
      "Paragraphs 18 and 19 are similar with a cosine similarity of [[0.33696036]]\n",
      "Paragraphs 19 and 20 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 20 and 21 are similar with a cosine similarity of [[0.37796447]]\n",
      "Paragraphs 21 and 22 are similar with a cosine similarity of [[0.38892223]]\n",
      "Paragraphs 22 and 23 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 23 and 24 are similar with a cosine similarity of [[0.15011733]]\n",
      "Paragraphs 24 and 25 are similar with a cosine similarity of [[0.08141255]]\n",
      "Paragraphs 25 and 26 are similar with a cosine similarity of [[0.12945594]]\n",
      "Paragraphs 26 and 27 are similar with a cosine similarity of [[0.29275844]]\n",
      "Paragraphs 27 and 28 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 28 and 29 are similar with a cosine similarity of [[0.34747055]]\n",
      "Paragraphs 29 and 30 are similar with a cosine similarity of [[0.19847907]]\n",
      "Paragraphs 30 and 31 are similar with a cosine similarity of [[0.17407766]]\n",
      "Paragraphs 31 and 32 are similar with a cosine similarity of [[0.25]]\n",
      "Paragraphs 32 and 33 are similar with a cosine similarity of [[0.47434165]]\n",
      "Paragraphs 33 and 34 are similar with a cosine similarity of [[0.39036003]]\n",
      "Paragraphs 34 and 35 are similar with a cosine similarity of [[0.25458754]]\n",
      "Paragraphs 35 and 36 are similar with a cosine similarity of [[0.11086502]]\n",
      "Paragraphs 36 and 37 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 37 and 38 are similar with a cosine similarity of [[0.32338083]]\n",
      "Paragraphs 38 and 39 are similar with a cosine similarity of [[0.4549742]]\n",
      "Paragraphs 39 and 40 are similar with a cosine similarity of [[0.32066911]]\n",
      "Paragraphs 40 and 41 are similar with a cosine similarity of [[0.29841884]]\n",
      "Paragraphs 41 and 42 are similar with a cosine similarity of [[0.15430335]]\n",
      "Paragraphs 42 and 43 are similar with a cosine similarity of [[0.30942637]]\n",
      "Paragraphs 43 and 44 are similar with a cosine similarity of [[0.1273214]]\n",
      "Paragraphs 44 and 45 are similar with a cosine similarity of [[0.23262105]]\n",
      "Paragraphs 45 and 46 are similar with a cosine similarity of [[0.09561222]]\n",
      "Paragraphs 46 and 47 are similar with a cosine similarity of [[0.20080594]]\n",
      "Paragraphs 47 and 48 are similar with a cosine similarity of [[0.02795813]]\n",
      "Paragraphs 48 and 49 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 49 and 50 are similar with a cosine similarity of [[0.23735633]]\n",
      "Paragraphs 50 and 51 are similar with a cosine similarity of [[0.05714869]]\n",
      "Paragraphs 51 and 52 are similar with a cosine similarity of [[0.24245662]]\n",
      "Paragraphs 52 and 53 are similar with a cosine similarity of [[0.02884949]]\n",
      "Paragraphs 53 and 54 are similar with a cosine similarity of [[0.01550807]]\n",
      "Paragraphs 54 and 55 are similar with a cosine similarity of [[0.0648675]]\n",
      "Paragraphs 55 and 56 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 56 and 57 are similar with a cosine similarity of [[0.0727393]]\n",
      "Paragraphs 57 and 58 are similar with a cosine similarity of [[0.29939248]]\n",
      "Paragraphs 58 and 59 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 59 and 60 are similar with a cosine similarity of [[0.34843657]]\n",
      "Paragraphs 60 and 61 are similar with a cosine similarity of [[0.20300518]]\n",
      "Paragraphs 61 and 62 are similar with a cosine similarity of [[0.42616136]]\n",
      "Paragraphs 62 and 63 are similar with a cosine similarity of [[0.27195904]]\n",
      "Paragraphs 63 and 64 are similar with a cosine similarity of [[0.33921896]]\n",
      "Paragraphs 64 and 65 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 65 and 66 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 66 and 67 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 67 and 68 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 68 and 69 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 69 and 70 are similar with a cosine similarity of [[0.08177754]]\n",
      "Paragraphs 70 and 71 are similar with a cosine similarity of [[0.07878386]]\n",
      "Paragraphs 71 and 72 are similar with a cosine similarity of [[0.08888889]]\n",
      "Paragraphs 72 and 73 are similar with a cosine similarity of [[0.1]]\n",
      "Paragraphs 73 and 74 are similar with a cosine similarity of [[0.08451543]]\n",
      "Paragraphs 74 and 75 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 75 and 76 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 76 and 77 are similar with a cosine similarity of [[0.37796447]]\n",
      "Paragraphs 77 and 78 are similar with a cosine similarity of [[0.3086067]]\n",
      "Paragraphs 78 and 79 are similar with a cosine similarity of [[0.66666667]]\n",
      "Paragraphs 79 and 80 are similar with a cosine similarity of [[0.45643546]]\n",
      "Paragraphs 80 and 81 are similar with a cosine similarity of [[0.1428869]]\n",
      "Paragraphs 81 and 82 are similar with a cosine similarity of [[0.04082483]]\n",
      "Paragraphs 82 and 83 are similar with a cosine similarity of [[0.0745356]]\n",
      "Paragraphs 83 and 84 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 84 and 85 are similar with a cosine similarity of [[0.24077171]]\n",
      "Paragraphs 85 and 86 are similar with a cosine similarity of [[0.15371887]]\n",
      "Paragraphs 86 and 87 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 87 and 88 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 88 and 89 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 89 and 90 are similar with a cosine similarity of [[0.16681153]]\n",
      "Paragraphs 90 and 91 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 91 and 92 are similar with a cosine similarity of [[0.04708816]]\n",
      "Paragraphs 92 and 93 are similar with a cosine similarity of [[0.06815982]]\n",
      "Paragraphs 93 and 94 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 94 and 95 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 95 and 96 are similar with a cosine similarity of [[0.0877058]]\n",
      "Paragraphs 96 and 97 are similar with a cosine similarity of [[0.07659644]]\n",
      "Paragraphs 97 and 98 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 98 and 99 are similar with a cosine similarity of [[0.2165464]]\n",
      "Paragraphs 99 and 100 are similar with a cosine similarity of [[0.15539539]]\n",
      "Paragraphs 100 and 101 are similar with a cosine similarity of [[0.45305913]]\n",
      "Paragraphs 101 and 102 are similar with a cosine similarity of [[0.38842762]]\n",
      "Paragraphs 102 and 103 are similar with a cosine similarity of [[0.42729162]]\n",
      "Paragraphs 103 and 104 are similar with a cosine similarity of [[0.25974026]]\n",
      "Paragraphs 104 and 105 are similar with a cosine similarity of [[0.14285714]]\n",
      "Paragraphs 105 and 106 are similar with a cosine similarity of [[0.30542361]]\n",
      "Paragraphs 106 and 107 are similar with a cosine similarity of [[0.28075724]]\n",
      "Paragraphs 107 and 108 are similar with a cosine similarity of [[0.39211294]]\n",
      "Paragraphs 108 and 109 are similar with a cosine similarity of [[0.05227084]]\n",
      "Paragraphs 109 and 110 are similar with a cosine similarity of [[0.24077171]]\n",
      "Paragraphs 110 and 111 are similar with a cosine similarity of [[0.05550799]]\n",
      "Paragraphs 111 and 112 are similar with a cosine similarity of [[0.08532145]]\n",
      "Paragraphs 112 and 113 are similar with a cosine similarity of [[0.13549163]]\n",
      "Paragraphs 113 and 114 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 114 and 115 are similar with a cosine similarity of [[0.21629523]]\n",
      "Paragraphs 115 and 116 are similar with a cosine similarity of [[0.25248661]]\n",
      "Paragraphs 116 and 117 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 117 and 118 are similar with a cosine similarity of [[0.27869321]]\n",
      "Paragraphs 118 and 119 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 119 and 120 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 120 and 121 are similar with a cosine similarity of [[0.21004201]]\n",
      "Paragraphs 121 and 122 are similar with a cosine similarity of [[0.14598929]]\n",
      "Paragraphs 122 and 123 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 123 and 124 are similar with a cosine similarity of [[0.]]\n",
      "Paragraphs 124 and 125 are similar with a cosine similarity of [[0.26726124]]\n",
      "Paragraphs 125 and 126 are similar with a cosine similarity of [[0.23473824]]\n",
      "Paragraphs 126 and 127 are similar with a cosine similarity of [[0.06195122]]\n"
     ]
    }
   ],
   "source": [
    "# Compute cosine similarity between two paragraphs\n",
    "# def cosine_similarity(p1, p2):\n",
    "#     return np.dot(p1, p2) / (np.linalg.norm(p1) * np.linalg.norm(p2))\n",
    "\n",
    "\n",
    "# Compute cosine similarity between all paragraphs two by two\n",
    "# for i in range(0, len(paragraphs) - 1):\n",
    "#     for j in range(i + 2, len(paragraphs) - 1):\n",
    "#         par1 = paragraphs[i]\n",
    "#         par2 = paragraphs[i + 1]\n",
    "#         par3 = paragraphs[j]\n",
    "#         par4 = paragraphs[j + 1]\n",
    "#         dict1 = paragraph_dict(par1, par2)\n",
    "#         dict2 = paragraph_dict(par3, par4)\n",
    "#         list1 = paragraph_list(dict1)\n",
    "#         list2 = paragraph_list(dict2)\n",
    "#         cos_sim = cosine_similarity([list1], [list2])\n",
    "#         print(f'Paragraphs {i} and {i + 1} are similar to paragraphs {j} and {j + 1} with a cosine similarity of {cos_sim}')\n",
    "\n",
    "# Compute cosine similarity between all paragraphs one by one\n",
    "for i in range(0, len(paragraphs) - 1):\n",
    "    par1 = paragraphs[i]\n",
    "    par2 = paragraphs[i + 1]\n",
    "    dict1 = paragraph_dict(par1)\n",
    "    dict2 = paragraph_dict(par2)\n",
    "    list1 = paragraph_list(dict1)\n",
    "    list2 = paragraph_list(dict2)\n",
    "    cos_sim = cosine_similarity([list1], [list2])\n",
    "    print(f'Paragraphs {i + 1} and {i + 2} are similar with a cosine similarity of {cos_sim}')\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
