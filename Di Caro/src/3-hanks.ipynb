{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 3 - Hanks\n",
    "\n",
    "## Idea\n",
    "- Il verbo scelto è **Love**\n",
    "- Si estrae dal corpus **Brown** le istanze che contengono il verbo **Love**\n",
    "- Si effettua parsing delle frasi estratte per cercare soggetti e oggetti relativi al verbo **Love**\n",
    "- Si cercano i super-sensi dei soggetti e degli oggetti\n",
    "- Si aggregano i risultati ottenuti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown\n",
    "from nltk.wsd import lesk\n",
    "from nltk.corpus import wordnet as wn\n",
    "import spacy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrai le frasi che contengono il verbo Love dal corpus Brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "verb = ['love', 'loves', 'loved']\n",
    "sentences = [sent for sent in brown.sents() if verb[0] in sent or verb[1] in sent or verb[2] in sent]\n",
    "print(len(sentences))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing delle frasi estratte per trovare il soggetto e l'oggetto del verbo Love\n",
    "\n",
    "Per ogni frase estratta dal corpus cerco il soggetto e l'oggetto del verbo **Love** e li salvo in una lista di tuple.  \n",
    "Per farlo uso la libreria **spaCy** che mi permette di cercare il soggetto e l'oggetto di un verbo in una frase tramite `token.dep_ == 'nsubj'` e `token.dep_ == 'dobj'`.  \n",
    "Tramite `token.head.text in verb` posso inoltre cercare se il soggetto e l'oggetto trovati sono effettivamente legati al verbo **Love**.  \n",
    "Restituisco una lista di triplette (soggetto, oggetto, frase) perché mi servirà la frase per disambiguare il soggetto e l'oggetto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the sentences using Spacy to extract the subject and object of the verb love\n",
    "def get_subject_object(sentence):\n",
    "    triples = []\n",
    "    for sent in sentences:\n",
    "        sub = ''\n",
    "        obj = ''\n",
    "        doc = nlp(' '.join(sent))\n",
    "        for token in doc:\n",
    "            if token.dep_ == 'nsubj' and token.head.text in verb:\n",
    "                sub = token.text\n",
    "            if token.dep_ == 'dobj' and token.head.text in verb:\n",
    "                obj = token.text\n",
    "        if sub != '' and obj != '':\n",
    "            triples.append((sub, obj, sent))\n",
    "    return triples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Disambiguazione delle coppie soggetto-oggetto\n",
    "\n",
    "Per ogni coppia soggetto-oggetto estratta dal corpus, cerco il super-senso di WordNet che meglio descrive il soggetto e l'oggetto. Per farlo utilizzo l'algoritmo di Lesk tramite la libreria **nltk**.  \n",
    "Se non trovo nessun super-senso per il soggetto o l'oggetto, inserisco di default \"noun.person\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the super senses of the subject and object\n",
    "def get_super_sense(triples):\n",
    "    super_senses = []\n",
    "    for triple in triples:\n",
    "        sub = triple[0]\n",
    "        obj = triple[1]\n",
    "        sent = triple[2]\n",
    "        sub_sense = lesk(sent, sub)\n",
    "        obj_sense = lesk(sent, obj)\n",
    "        super_senses.append((sub_sense.lexname() if sub_sense else 'noun.person', obj_sense.lexname() if obj_sense else 'noun.person'))\n",
    "    return super_senses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregazione dei risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Different pairs: 35\n",
      "('noun.person', 'noun.person'): 22.22%\n",
      "('noun.substance', 'noun.person'): 12.50%\n",
      "('adj.all', 'noun.person'): 5.56%\n",
      "('noun.person', 'noun.cognition'): 4.17%\n",
      "('noun.group', 'noun.person'): 4.17%\n",
      "('noun.person', 'noun.group'): 4.17%\n",
      "('noun.person', 'noun.attribute'): 2.78%\n",
      "('noun.substance', 'noun.group'): 2.78%\n",
      "('adj.all', 'verb.creation'): 2.78%\n",
      "('noun.substance', 'noun.location'): 2.78%\n",
      "('noun.person', 'noun.location'): 2.78%\n",
      "('noun.group', 'verb.body'): 1.39%\n",
      "('noun.person', 'verb.motion'): 1.39%\n",
      "('noun.person', 'noun.Tops'): 1.39%\n",
      "('noun.group', 'verb.cognition'): 1.39%\n",
      "('noun.group', 'noun.location'): 1.39%\n",
      "('noun.substance', 'verb.emotion'): 1.39%\n",
      "('noun.group', 'noun.cognition'): 1.39%\n",
      "('adj.all', 'verb.communication'): 1.39%\n",
      "('noun.substance', 'noun.cognition'): 1.39%\n",
      "('noun.person', 'noun.artifact'): 1.39%\n",
      "('noun.group', 'noun.feeling'): 1.39%\n",
      "('verb.stative', 'noun.location'): 1.39%\n",
      "('noun.state', 'noun.cognition'): 1.39%\n",
      "('noun.substance', 'noun.artifact'): 1.39%\n",
      "('adj.all', 'adj.all'): 1.39%\n",
      "('adj.all', 'verb.stative'): 1.39%\n",
      "('noun.time', 'noun.person'): 1.39%\n",
      "('noun.person', 'verb.social'): 1.39%\n",
      "('noun.quantity', 'noun.object'): 1.39%\n",
      "('noun.substance', 'noun.feeling'): 1.39%\n",
      "('noun.person', 'noun.act'): 1.39%\n",
      "('noun.person', 'adj.all'): 1.39%\n",
      "('noun.Tops', 'noun.location'): 1.39%\n",
      "('noun.substance', 'verb.change'): 1.39%\n"
     ]
    }
   ],
   "source": [
    "# Aggregate the super senses\n",
    "def aggregate_super_sense(super_senses):\n",
    "    super_sense_dict = {}\n",
    "    for super_sense in super_senses:\n",
    "        if super_sense in super_sense_dict:\n",
    "            super_sense_dict[super_sense] += 1\n",
    "        else:\n",
    "            super_sense_dict[super_sense] = 1\n",
    "    super_sense_dict = {k: v for k, v in sorted(super_sense_dict.items(), key=lambda item: item[1], reverse=True)}\n",
    "    return super_sense_dict\n",
    "\n",
    "result = aggregate_super_sense(get_super_sense(get_subject_object(sentences)))\n",
    "total = sum(result.values())\n",
    "print(f'Different pairs: {len(result)}')\n",
    "for key, value in result.items():\n",
    "    print(f'{key}: {value/total*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1 (v3.9.1:1e5d33e9b9, Dec  7 2020, 12:10:52) \n[Clang 6.0 (clang-600.0.57)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
