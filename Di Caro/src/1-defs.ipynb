{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizio 1 - Definizioni\n",
    "\n",
    "Lo scopo dell'esercizio è determinare la similarità delle definizioni date dagli studenti per i seguenti termini:\n",
    "\n",
    "|  | Generico | Specifico |\n",
    "|:--------:|:--------:|:---------:|\n",
    "| **Concreto** | Person | Brick |\n",
    "| **Astratto** | Emotion | Revenge |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leggi il file di input\n",
    "\n",
    "Salvo le varie definizioni degli studenti in un dizionario con:\n",
    "- chiave: parola (in ordine Emotion, Person, Revenge, Brick)\n",
    "- valore: lista di definizioni date dagli studenti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('../data/definizioni.xlsx')\n",
    "students = df.columns[1:].tolist()\n",
    "words = df[df.columns[0]].tolist()\n",
    "def_dict = {}\n",
    "for definition in words:\n",
    "    def_dict[definition] = []\n",
    "for student in students:\n",
    "    for definition in words:\n",
    "        def_dict[definition].append(df[student][df[df.columns[0]] == definition].values[0])\n",
    "\n",
    "# def_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ripulisci il dictionary delle definizioni\n",
    "\n",
    "Salvo le definizioni pulite in un dizionario strutturato come il precedente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# Tokenize and lemmatize definitions and remove stopwords and punctuation\n",
    "def clean_definitions(dict):\n",
    "    cleaned = dict.copy()\n",
    "    for key in cleaned:\n",
    "        definitions = [d for d in cleaned[key] if d == d]\n",
    "        tmp = []\n",
    "        for definition in definitions:\n",
    "            tmp.append([lemmatizer.lemmatize(token.lower()) for token in tokenizer.tokenize(definition) if token.lower() not in stopwords])\n",
    "        cleaned[key] = tmp\n",
    "    return cleaned\n",
    "\n",
    "clean_def_dict = clean_definitions(def_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcola la similarità tra le definizioni\n",
    "\n",
    "Per ogni parola, calcolo le *n* parole più frequenti nelle definizioni date dagli studenti, usando la funzione `most_common` di `Counter`.  \n",
    "Per calcolare la similarità tra le definizioni, calcolo la media delle volte che le parole più frequenti compaiono nelle definizioni, data da:  \n",
    "numero di volte che le parole più frequenti compaiono in una definizione / numero di definizioni.  \n",
    "Infine la similarità totale è data da:  \n",
    "somma delle medie di ogni parola frequente / numero di parole frequenti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Considering the 5 most frequent words\n",
      "Word: Emotion\n",
      "Similarity: 0.2733333333333333\n",
      "\n",
      "Word: Person\n",
      "Similarity: 0.2903225806451612\n",
      "\n",
      "Word: Revenge\n",
      "Similarity: 0.2733333333333333\n",
      "\n",
      "Word: Brick\n",
      "Similarity: 0.5483870967741935\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the most common words in the definitions of a word\n",
    "def get_common_words(dict, word, n):\n",
    "    words = []\n",
    "    for definition in dict[word]:\n",
    "        words += definition\n",
    "    return Counter(words).most_common(n)\n",
    "\n",
    "# Get mean number of times a frequent word appears in the definitions of a word\n",
    "def get_mean_freq(dict, word, freq_word):\n",
    "    return freq_word[1]/len(dict[word])\n",
    "\n",
    "# Get total similarity of definitions of a word as the overall mean of frequent words\n",
    "def similarity(dict, word, n):\n",
    "    freq_words = get_common_words(dict, word, n)\n",
    "    mean = 0\n",
    "    for freq_word in freq_words:\n",
    "        mean += get_mean_freq(dict, word, freq_word)\n",
    "    return mean/n\n",
    "\n",
    "# Print the similarity of each word\n",
    "n_freq_words = 5\n",
    "print(f'Considering the {n_freq_words} most frequent words')\n",
    "for word in clean_def_dict:\n",
    "    print(f'Word: {word}')\n",
    "    print(f'Similarity: {similarity(clean_def_dict, word, n_freq_words)}\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 08:50:36) \n[Clang 10.0.0 ]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5587bf738ccec4bb524b17f914a1c07eb93a384af8fabdf9504251bc61fb6171"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
